{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metodos responsaveis pelo pre processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ra9yOmFHfx_"
   },
   "source": [
    "# Com Outliers  Com Normalização Sem Unamed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dlnh14LdD5K-",
    "outputId": "26bca585-4751-40cf-f0b2-700d4466af4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 146 entries, 1005 to 52861\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   carat    146 non-null    float64\n",
      " 1   cut      146 non-null    object \n",
      " 2   color    146 non-null    object \n",
      " 3   clarity  146 non-null    object \n",
      " 4   depth    146 non-null    float64\n",
      " 5   table    146 non-null    float64\n",
      " 6   price    146 non-null    int64  \n",
      " 7   x        146 non-null    float64\n",
      " 8   y        146 non-null    float64\n",
      " 9   z        146 non-null    float64\n",
      "dtypes: float64(6), int64(1), object(3)\n",
      "memory usage: 12.5+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### LinearRegression ####\n",
      "score :0.8603\n",
      "[0.85929859 0.8546376  0.86308003 0.85616085 0.85896936]\n",
      "\n",
      "MSE    : 2171054.35 \n",
      "MAE    : 894.87 \n",
      "RMSE   : 1473.45 \n",
      "R2     : 0.86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   53.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### RandomForestRegressor ####\n",
      "score :0.8805\n",
      "[0.87318664 0.8786663  0.88398218 0.8737674  0.87813642]\n",
      "\n",
      "MSE    : 1857131.04 \n",
      "MAE    : 783.80 \n",
      "RMSE   : 1362.77 \n",
      "R2     : 0.88 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### KNeighborsRegressor ####\n",
      "score :0.8666\n",
      "[0.86201044 0.86328527 0.86735416 0.86217312 0.86233278]\n",
      "\n",
      "MSE    : 2072497.17 \n",
      "MAE    : 821.10 \n",
      "RMSE   : 1439.62 \n",
      "R2     : 0.87 \n",
      "Iteration 1, loss = 1703431.03922542\n",
      "Iteration 2, loss = 1196819.33054975\n",
      "Iteration 3, loss = 1195348.85966304\n",
      "Iteration 4, loss = 1182228.01488569\n",
      "Iteration 5, loss = 1165707.55978305\n",
      "Iteration 6, loss = 1161874.46641999\n",
      "Iteration 7, loss = 1142836.50931182\n",
      "Iteration 8, loss = 1123335.43861061\n",
      "Iteration 9, loss = 1098933.74375387\n",
      "Iteration 10, loss = 1078793.54564813\n",
      "Iteration 11, loss = 1068946.10257604\n",
      "Iteration 12, loss = 1060992.93250390\n",
      "Iteration 13, loss = 1055270.80084534\n",
      "Iteration 14, loss = 1057064.64507844\n",
      "Iteration 15, loss = 1062171.34976387\n",
      "Iteration 16, loss = 1052266.47867615\n",
      "Iteration 17, loss = 1047215.39148200\n",
      "Iteration 18, loss = 1052628.68497232\n",
      "Iteration 19, loss = 1049503.50577366\n",
      "Iteration 20, loss = 1048195.94993412\n",
      "Iteration 21, loss = 1046628.11082287\n",
      "Iteration 22, loss = 1043570.29053100\n",
      "Iteration 23, loss = 1046290.49969451\n",
      "Iteration 24, loss = 1045440.52778772\n",
      "Iteration 25, loss = 1039460.58339008\n",
      "Iteration 26, loss = 1042420.84176905\n",
      "Iteration 27, loss = 1042178.20062726\n",
      "Iteration 28, loss = 1038586.80885851\n",
      "Iteration 29, loss = 1044402.39367445\n",
      "Iteration 30, loss = 1039032.56398946\n",
      "Iteration 31, loss = 1040719.13143729\n",
      "Iteration 32, loss = 1035127.61040753\n",
      "Iteration 33, loss = 1038285.30710341\n",
      "Iteration 34, loss = 1039135.99924494\n",
      "Iteration 35, loss = 1037383.94897294\n",
      "Iteration 36, loss = 1035608.84863579\n",
      "Iteration 37, loss = 1036734.66701174\n",
      "Iteration 38, loss = 1032967.15150323\n",
      "Iteration 39, loss = 1037890.58207034\n",
      "Iteration 40, loss = 1035434.58036795\n",
      "Iteration 41, loss = 1033595.70797660\n",
      "Iteration 42, loss = 1035797.02818994\n",
      "Iteration 43, loss = 1033891.81347264\n",
      "Iteration 44, loss = 1031247.67996245\n",
      "Iteration 45, loss = 1035957.70118461\n",
      "Iteration 46, loss = 1034402.74164323\n",
      "Iteration 47, loss = 1035129.22474364\n",
      "Iteration 48, loss = 1037232.25728904\n",
      "Iteration 49, loss = 1035350.20251895\n",
      "Iteration 50, loss = 1036677.33867865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### MLPRegressor ####\n",
      "score :0.8667\n",
      "[0.87120285 0.87235221 0.87954498 0.86523996 0.8688524 ]\n",
      "\n",
      "MSE    : 2071728.35 \n",
      "MAE    : 811.80 \n",
      "RMSE   : 1439.35 \n",
      "R2     : 0.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 17.2min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Test score</th>\n",
       "      <th>CV Train score (mean)</th>\n",
       "      <th>%%SVGean Squared error</th>\n",
       "      <th>Mean Absolute error</th>\n",
       "      <th>Root Mean Squared error</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.860279</td>\n",
       "      <td>0.858429</td>\n",
       "      <td>2.171054e+06</td>\n",
       "      <td>894.867543</td>\n",
       "      <td>1473.449812</td>\n",
       "      <td>0.860279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.880482</td>\n",
       "      <td>0.877548</td>\n",
       "      <td>1.857131e+06</td>\n",
       "      <td>783.801237</td>\n",
       "      <td>1362.765953</td>\n",
       "      <td>0.880482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.866622</td>\n",
       "      <td>0.863431</td>\n",
       "      <td>2.072497e+06</td>\n",
       "      <td>821.099907</td>\n",
       "      <td>1439.617022</td>\n",
       "      <td>0.866622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>0.866671</td>\n",
       "      <td>0.871438</td>\n",
       "      <td>2.071728e+06</td>\n",
       "      <td>811.799108</td>\n",
       "      <td>1439.349976</td>\n",
       "      <td>0.866671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  CV Test score  ...  Root Mean Squared error  R2 Score\n",
       "0       LinearRegression       0.860279  ...              1473.449812  0.860279\n",
       "1  RandomForestRegressor       0.880482  ...              1362.765953  0.880482\n",
       "2    KNeighborsRegressor       0.866622  ...              1439.617022  0.866622\n",
       "3           MLPRegressor       0.866671  ...              1439.349976  0.866671\n",
       "\n",
       "[4 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "df_diamonds = pd.read_csv('datasets/diamonds.csv')\n",
    "df_diamonds = df_diamonds.drop(df_diamonds.columns[[0]], axis=1)\n",
    "df_number_type = df_diamonds.select_dtypes(exclude='O')\n",
    "\n",
    "df_diamonds[df_diamonds.duplicated()].info()\n",
    "\n",
    "y=df_number_type['price']\n",
    "X=df_number_type.drop('price', axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=0.2, random_state=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sc=StandardScaler()\n",
    "X_train_tx=sc.fit_transform(X_train)\n",
    "X_test_tx=sc.transform(X_test)\n",
    "\n",
    "dataset_1=(X_train, X_test, y_train, y_test, 'dataset_1')\n",
    "\n",
    "model_=[]\n",
    "cv_score_test=[]\n",
    "cv_score_train=[]\n",
    "mse_=[]\n",
    "mae_=[]\n",
    "rmse_=[]\n",
    "r2_=[]\n",
    "\n",
    "\n",
    "def run_model(model, dataset, modelname):\n",
    "    model.fit(dataset[0], dataset[2])\n",
    "    accuracies=cross_val_score(n_jobs=-1, estimator=model, X=dataset[0], y=dataset[2], cv=5, verbose=1)\n",
    "    y_pred=model.predict(dataset[1])\n",
    "    print('')\n",
    "    score_1=model.score(dataset[1], dataset[3])\n",
    "    print(f'#### {modelname} ####')\n",
    "    print(\"score :%.4f\" %score_1)\n",
    "    print(accuracies)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(dataset[3], y_pred)\n",
    "    mae=mean_absolute_error(dataset[3], y_pred)\n",
    "    rmse=mean_squared_error(dataset[3], y_pred)**0.5\n",
    "    r2=r2_score(dataset[3], y_pred)\n",
    "   \n",
    "    \n",
    "    print('')\n",
    "    print('MSE    : %0.2f ' % mse)\n",
    "    print('MAE    : %0.2f ' % mae)\n",
    "    print('RMSE   : %0.2f ' % rmse)\n",
    "    print('R2     : %0.2f ' % r2)\n",
    "    \n",
    "    \n",
    "    model_.append(modelname)\n",
    "    cv_score_test.append(score_1)\n",
    "    cv_score_train.append(np.mean(accuracies))\n",
    "    mse_.append(mse)\n",
    "    mae_.append(mae)\n",
    "    rmse_.append(rmse)\n",
    "    r2_.append(r2)\n",
    "\n",
    "\n",
    "model_dict={'LinearRegression': LinearRegression(),\n",
    "           'RandomForestRegressor': RandomForestRegressor(), \n",
    "           'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "            'MLPRegressor': MLPRegressor(hidden_layer_sizes=(100,), batch_size=2, learning_rate_init=0.01, learning_rate=\"adaptive\", max_iter=50, verbose=True)\n",
    "\n",
    "           }\n",
    "\n",
    "for models in model_dict:\n",
    "    run_model(model_dict[models], dataset_1, models)\n",
    "\n",
    "accuracy_data=pd.DataFrame(zip(model_, cv_score_test, cv_score_train, mse_, mae_, rmse_, r2_), columns=['Model', 'CV Test score', 'CV Train score (mean)', '%%SVGean Squared error', 'Mean Absolute error', 'Root Mean Squared error', 'R2 Score'])\n",
    "\n",
    "accuracy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_8XJyRJpwqD"
   },
   "source": [
    "# Com Outliers  Com Normalização com *unamed*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-R_fMLREqDh_",
    "outputId": "30ba9d73-9fb8-4db1-e2a9-20eaf2b56383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 0 entries\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  0 non-null      int64  \n",
      " 1   carat       0 non-null      float64\n",
      " 2   cut         0 non-null      object \n",
      " 3   color       0 non-null      object \n",
      " 4   clarity     0 non-null      object \n",
      " 5   depth       0 non-null      float64\n",
      " 6   table       0 non-null      float64\n",
      " 7   price       0 non-null      int64  \n",
      " 8   x           0 non-null      float64\n",
      " 9   y           0 non-null      float64\n",
      " 10  z           0 non-null      float64\n",
      "dtypes: float64(6), int64(2), object(3)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### LinearRegression ####\n",
      "score :0.8611\n",
      "[0.8601141  0.85515871 0.86385021 0.85686318 0.85983774]\n",
      "\n",
      "MSE    : 2158838.67 \n",
      "MAE    : 905.55 \n",
      "RMSE   : 1469.30 \n",
      "R2     : 0.86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   59.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### RandomForestRegressor ####\n",
      "score :0.9999\n",
      "[0.99985466 0.99982998 0.9998968  0.99981602 0.99989272]\n",
      "\n",
      "MSE    : 1565.70 \n",
      "MAE    : 5.66 \n",
      "RMSE   : 39.57 \n",
      "R2     : 1.00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### KNeighborsRegressor ####\n",
      "score :0.9935\n",
      "[0.99312903 0.99454886 0.99431777 0.99525537 0.99247625]\n",
      "\n",
      "MSE    : 101363.53 \n",
      "MAE    : 34.67 \n",
      "RMSE   : 318.38 \n",
      "R2     : 0.99 \n",
      "Iteration 1, loss = 5717251.49619160\n",
      "Iteration 2, loss = 3583539.73940808\n",
      "Iteration 3, loss = 2111735.28782188\n",
      "Iteration 4, loss = 1497535.91803554\n",
      "Iteration 5, loss = 1305675.65054641\n",
      "Iteration 6, loss = 1201616.36543659\n",
      "Iteration 7, loss = 1151017.42938439\n",
      "Iteration 8, loss = 1083416.94304019\n",
      "Iteration 9, loss = 1056419.13939117\n",
      "Iteration 10, loss = 1059493.73382037\n",
      "Iteration 11, loss = 985309.32688432\n",
      "Iteration 12, loss = 956402.82447833\n",
      "Iteration 13, loss = 944771.60399517\n",
      "Iteration 14, loss = 931743.35224766\n",
      "Iteration 15, loss = 929797.90310595\n",
      "Iteration 16, loss = 904190.06771975\n",
      "Iteration 17, loss = 885858.53133951\n",
      "Iteration 18, loss = 870363.41384105\n",
      "Iteration 19, loss = 885656.46774221\n",
      "Iteration 20, loss = 875109.15440402\n",
      "Iteration 21, loss = 864968.46605057\n",
      "Iteration 22, loss = 864017.61835826\n",
      "Iteration 23, loss = 840262.78859275\n",
      "Iteration 24, loss = 835120.57064033\n",
      "Iteration 25, loss = 816813.08945420\n",
      "Iteration 26, loss = 813777.21771712\n",
      "Iteration 27, loss = 814747.25282448\n",
      "Iteration 28, loss = 802047.97722882\n",
      "Iteration 29, loss = 815627.52534858\n",
      "Iteration 30, loss = 794775.52650722\n",
      "Iteration 31, loss = 798213.64625320\n",
      "Iteration 32, loss = 782526.40260216\n",
      "Iteration 33, loss = 775690.07077227\n",
      "Iteration 34, loss = 788309.30674928\n",
      "Iteration 35, loss = 782951.25958843\n",
      "Iteration 36, loss = 756306.97569625\n",
      "Iteration 37, loss = 778852.24803344\n",
      "Iteration 38, loss = 767565.56196856\n",
      "Iteration 39, loss = 774588.46515773\n",
      "Iteration 40, loss = 759956.81264491\n",
      "Iteration 41, loss = 752850.67469635\n",
      "Iteration 42, loss = 744043.17352094\n",
      "Iteration 43, loss = 749244.52303963\n",
      "Iteration 44, loss = 742537.71101111\n",
      "Iteration 45, loss = 724926.02765635\n",
      "Iteration 46, loss = 744602.89855557\n",
      "Iteration 47, loss = 743564.39544740\n",
      "Iteration 48, loss = 737168.75129300\n",
      "Iteration 49, loss = 735394.33944828\n",
      "Iteration 50, loss = 733644.99817137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### MLPRegressor ####\n",
      "score :0.9367\n",
      "[0.93478928 0.92131464 0.83109559 0.91679391 0.93216548]\n",
      "\n",
      "MSE    : 982947.51 \n",
      "MAE    : 698.70 \n",
      "RMSE   : 991.44 \n",
      "R2     : 0.94 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 17.4min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Test score</th>\n",
       "      <th>CV Train score (mean)</th>\n",
       "      <th>%%SVGean Squared error</th>\n",
       "      <th>Mean Absolute error</th>\n",
       "      <th>Root Mean Squared error</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.861065</td>\n",
       "      <td>0.859165</td>\n",
       "      <td>2.158839e+06</td>\n",
       "      <td>905.550440</td>\n",
       "      <td>1469.298701</td>\n",
       "      <td>0.861065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>1.565696e+03</td>\n",
       "      <td>5.662420</td>\n",
       "      <td>39.568878</td>\n",
       "      <td>0.999899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.993477</td>\n",
       "      <td>0.993945</td>\n",
       "      <td>1.013635e+05</td>\n",
       "      <td>34.670337</td>\n",
       "      <td>318.376394</td>\n",
       "      <td>0.993477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>0.936741</td>\n",
       "      <td>0.907232</td>\n",
       "      <td>9.829475e+05</td>\n",
       "      <td>698.699120</td>\n",
       "      <td>991.437093</td>\n",
       "      <td>0.936741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  CV Test score  ...  Root Mean Squared error  R2 Score\n",
       "0       LinearRegression       0.861065  ...              1469.298701  0.861065\n",
       "1  RandomForestRegressor       0.999899  ...                39.568878  0.999899\n",
       "2    KNeighborsRegressor       0.993477  ...               318.376394  0.993477\n",
       "3           MLPRegressor       0.936741  ...               991.437093  0.936741\n",
       "\n",
       "[4 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd# Aprendizado de Comitês\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "df_diamonds = pd.read_csv('datasets/diamonds.csv')\n",
    "df_diamonds[df_diamonds.duplicated()].info()\n",
    "df_number_type = df_diamonds.select_dtypes(exclude='O')\n",
    "\n",
    "\n",
    "y=df_number_type['price']\n",
    "X=df_number_type.drop('price', axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=0.2, random_state=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "sc=StandardScaler()\n",
    "X_train_tx=sc.fit_transform(X_train)\n",
    "X_test_tx=sc.transform(X_test)\n",
    "\n",
    "dataset_1=(X_train, X_test, y_train, y_test, 'dataset_1')\n",
    "\n",
    "# Blank lists for all the details\n",
    "model_=[]\n",
    "cv_score_test=[]\n",
    "cv_score_train=[]\n",
    "mse_=[]\n",
    "mae_=[]\n",
    "rmse_=[]\n",
    "r2_=[]\n",
    "\n",
    "\n",
    "def run_model(model, dataset, modelname):\n",
    "    model.fit(dataset[0], dataset[2])\n",
    "    accuracies=cross_val_score(n_jobs=-1, estimator=model, X=dataset[0], y=dataset[2], cv=5, verbose=1)\n",
    "    y_pred=model.predict(dataset[1])\n",
    "    print('')\n",
    "    score_1=model.score(dataset[1], dataset[3])\n",
    "    print(f'#### {modelname} ####')\n",
    "    print(\"score :%.4f\" %score_1)\n",
    "    print(accuracies)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(dataset[3], y_pred)\n",
    "    mae=mean_absolute_error(dataset[3], y_pred)\n",
    "    rmse=mean_squared_error(dataset[3], y_pred)**0.5\n",
    "    r2=r2_score(dataset[3], y_pred)\n",
    "   \n",
    "    \n",
    "    print('')\n",
    "    print('MSE    : %0.2f ' % mse)\n",
    "    print('MAE    : %0.2f ' % mae)\n",
    "    print('RMSE   : %0.2f ' % rmse)\n",
    "    print('R2     : %0.2f ' % r2)\n",
    "    \n",
    "    ## appending to the lists\n",
    "    \n",
    "    model_.append(modelname)\n",
    "    cv_score_test.append(score_1)\n",
    "    cv_score_train.append(np.mean(accuracies))\n",
    "    mse_.append(mse)\n",
    "    mae_.append(mae)\n",
    "    rmse_.append(rmse)\n",
    "    r2_.append(r2)\n",
    "\n",
    "\n",
    "model_dict={'LinearRegression': LinearRegression(),\n",
    "           'RandomForestRegressor': RandomForestRegressor(), \n",
    "           'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "           'MLPRegressor': MLPRegressor(hidden_layer_sizes=(100,), batch_size=2, learning_rate_init=0.01, learning_rate=\"adaptive\", max_iter=50, verbose=True)\n",
    "           }\n",
    "\n",
    "for models in model_dict:\n",
    "    run_model(model_dict[models], dataset_1, models)\n",
    "\n",
    "accuracy_data=pd.DataFrame(zip(model_, cv_score_test, cv_score_train, mse_, mae_, rmse_, r2_), columns=['Model', 'CV Test score', 'CV Train score (mean)', '%%SVGean Squared error', 'Mean Absolute error', 'Root Mean Squared error', 'R2 Score'])\n",
    "\n",
    "accuracy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osq0d5r-2ly7"
   },
   "source": [
    "# Com outliers sem normalizacao sem Unamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5T_If7Y2siY",
    "outputId": "7310c2a2-8b09-45ca-a039-4434f84c20b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 146 entries, 1005 to 52861\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   carat    146 non-null    float64\n",
      " 1   cut      146 non-null    object \n",
      " 2   color    146 non-null    object \n",
      " 3   clarity  146 non-null    object \n",
      " 4   depth    146 non-null    float64\n",
      " 5   table    146 non-null    float64\n",
      " 6   price    146 non-null    int64  \n",
      " 7   x        146 non-null    float64\n",
      " 8   y        146 non-null    float64\n",
      " 9   z        146 non-null    float64\n",
      "dtypes: float64(6), int64(1), object(3)\n",
      "memory usage: 12.5+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### LinearRegression ####\n",
      "score :0.8603\n",
      "[0.85929859 0.8546376  0.86308003 0.85616085 0.85896936]\n",
      "\n",
      "MSE    : 2171054.35 \n",
      "MAE    : 894.87 \n",
      "RMSE   : 1473.45 \n",
      "R2     : 0.86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e9dd6698e8b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0maccuracy_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_score_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_score_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CV Test score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CV Train score (mean)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%%SVGean Squared error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mean Absolute error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Root Mean Squared error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'R2 Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e9dd6698e8b7>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, dataset, modelname)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0maccuracies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mestrado-materias/mineracao-dados/projeto-final/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mestrado-materias/mineracao-dados/projeto-final/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mestrado-materias/mineracao-dados/projeto-final/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mestrado-materias/mineracao-dados/projeto-final/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 242\u001b[0;31m     scores = parallel(\n\u001b[0m\u001b[1;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mestrado-materias/mineracao-dados/projeto-final/venv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mestrado-materias/mineracao-dados/projeto-final/venv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mestrado-materias/mineracao-dados/projeto-final/venv/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd# Aprendizado de Comitês\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "df_diamonds = pd.read_csv('datasets/diamonds.csv')\n",
    "df_diamonds = df_diamonds.drop(df_diamonds.columns[[0]], axis=1)\n",
    "\n",
    "df_diamonds[df_diamonds.duplicated()].info()\n",
    "df_number_type = df_diamonds.select_dtypes(exclude='O')\n",
    "\n",
    "\n",
    "y=df_number_type['price']\n",
    "X=df_number_type.drop('price', axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=0.2, random_state=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "# sc=StandardScaler()\n",
    "# X_train_tx=sc.fit_transform(X_train)\n",
    "# X_test_tx=sc.transform(X_test)\n",
    "\n",
    "dataset_1=(X_train, X_test, y_train, y_test, 'dataset_1')\n",
    "\n",
    "# Blank lists for all the details\n",
    "model_=[]\n",
    "cv_score_test=[]\n",
    "cv_score_train=[]\n",
    "mse_=[]\n",
    "mae_=[]\n",
    "rmse_=[]\n",
    "r2_=[]\n",
    "\n",
    "\n",
    "def run_model(model, dataset, modelname):\n",
    "    model.fit(dataset[0], dataset[2])\n",
    "    accuracies=cross_val_score(n_jobs=-1, estimator=model, X=dataset[0], y=dataset[2], cv=5, verbose=1)\n",
    "    y_pred=model.predict(dataset[1])\n",
    "    print('')\n",
    "    score_1=model.score(dataset[1], dataset[3])\n",
    "    print(f'#### {modelname} ####')\n",
    "    print(\"score :%.4f\" %score_1)\n",
    "    print(accuracies)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(dataset[3], y_pred)\n",
    "    mae=mean_absolute_error(dataset[3], y_pred)\n",
    "    rmse=mean_squared_error(dataset[3], y_pred)**0.5\n",
    "    r2=r2_score(dataset[3], y_pred)\n",
    "   \n",
    "    \n",
    "    print('')\n",
    "    print('MSE    : %0.2f ' % mse)\n",
    "    print('MAE    : %0.2f ' % mae)\n",
    "    print('RMSE   : %0.2f ' % rmse)\n",
    "    print('R2     : %0.2f ' % r2)\n",
    "    \n",
    "    ## appending to the lists\n",
    "    \n",
    "    model_.append(modelname)\n",
    "    cv_score_test.append(score_1)\n",
    "    cv_score_train.append(np.mean(accuracies))\n",
    "    mse_.append(mse)\n",
    "    mae_.append(mae)\n",
    "    rmse_.append(rmse)\n",
    "    r2_.append(r2)\n",
    "\n",
    "\n",
    "model_dict={'LinearRegression': LinearRegression(),\n",
    "           'RandomForestRegressor': RandomForestRegressor(), \n",
    "           'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "           'MLPRegressor': MLPRegressor(hidden_layer_sizes=(100,), batch_size=2, learning_rate_init=0.01, learning_rate=\"adaptive\", max_iter=50, verbose=True)\n",
    "           }\n",
    "\n",
    "for models in model_dict:\n",
    "    run_model(model_dict[models], dataset_1, models)\n",
    "\n",
    "accuracy_data=pd.DataFrame(zip(model_, cv_score_test, cv_score_train, mse_, mae_, rmse_, r2_), columns=['Model', 'CV Test score', 'CV Train score (mean)', '%%SVGean Squared error', 'Mean Absolute error', 'Root Mean Squared error', 'R2 Score'])\n",
    "\n",
    "accuracy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXd_qICpquaz"
   },
   "source": [
    "# Sem Outliers  Com Normalização com *unamed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ah5wBpLdq2fj",
    "outputId": "f9069a9a-7c7a-4aff-bd89-17f469e41c25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 0 entries\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  0 non-null      int64  \n",
      " 1   carat       0 non-null      float64\n",
      " 2   cut         0 non-null      object \n",
      " 3   color       0 non-null      object \n",
      " 4   clarity     0 non-null      object \n",
      " 5   depth       0 non-null      float64\n",
      " 6   table       0 non-null      float64\n",
      " 7   price       0 non-null      int64  \n",
      " 8   x           0 non-null      float64\n",
      " 9   y           0 non-null      float64\n",
      " 10  z           0 non-null      float64\n",
      "dtypes: float64(6), int64(2), object(3)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### LinearRegression ####\n",
      "score :0.8611\n",
      "[0.8508012  0.86313829 0.86698611 0.86094914 0.86214544]\n",
      "\n",
      "MSE    : 1016587.99 \n",
      "MAE    : 627.90 \n",
      "RMSE   : 1008.26 \n",
      "R2     : 0.86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### RandomForestRegressor ####\n",
      "score :0.9998\n",
      "[0.99969099 0.99963411 0.99971844 0.99975671 0.9998425 ]\n",
      "\n",
      "MSE    : 1438.55 \n",
      "MAE    : 6.74 \n",
      "RMSE   : 37.93 \n",
      "R2     : 1.00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### KNeighborsRegressor ####\n",
      "score :0.9947\n",
      "[0.98901651 0.99019119 0.98773833 0.99005624 0.98970058]\n",
      "\n",
      "MSE    : 38835.63 \n",
      "MAE    : 25.94 \n",
      "RMSE   : 197.07 \n",
      "R2     : 0.99 \n",
      "Iteration 1, loss = 2679462.66773641\n",
      "Iteration 2, loss = 1276130.23038648\n",
      "Iteration 3, loss = 775289.43802786\n",
      "Iteration 4, loss = 691287.36507850\n",
      "Iteration 5, loss = 626101.17130588\n",
      "Iteration 6, loss = 546915.20265066\n",
      "Iteration 7, loss = 499588.66282900\n",
      "Iteration 8, loss = 456675.01124959\n",
      "Iteration 9, loss = 448772.73967857\n",
      "Iteration 10, loss = 447288.16231059\n",
      "Iteration 11, loss = 428611.01992367\n",
      "Iteration 12, loss = 422053.35116102\n",
      "Iteration 13, loss = 404230.42599598\n",
      "Iteration 14, loss = 393902.14717621\n",
      "Iteration 15, loss = 382681.16022808\n",
      "Iteration 16, loss = 380119.85438786\n",
      "Iteration 17, loss = 374387.64516109\n",
      "Iteration 18, loss = 372968.48243640\n",
      "Iteration 19, loss = 368921.36554043\n",
      "Iteration 20, loss = 362940.66534379\n",
      "Iteration 21, loss = 366229.95793564\n",
      "Iteration 22, loss = 347278.70250470\n",
      "Iteration 23, loss = 350701.14872800\n",
      "Iteration 24, loss = 342417.95655178\n",
      "Iteration 25, loss = 337145.65541683\n",
      "Iteration 26, loss = 333982.72707865\n",
      "Iteration 27, loss = 318912.84420369\n",
      "Iteration 28, loss = 324858.68598220\n",
      "Iteration 29, loss = 327179.38281817\n",
      "Iteration 30, loss = 313742.91582659\n",
      "Iteration 31, loss = 323327.45866902\n",
      "Iteration 32, loss = 321287.74860225\n",
      "Iteration 33, loss = 316604.73532807\n",
      "Iteration 34, loss = 317560.87335815\n",
      "Iteration 35, loss = 306941.51662848\n",
      "Iteration 36, loss = 308719.16733112\n",
      "Iteration 37, loss = 306058.95420044\n",
      "Iteration 38, loss = 311383.63486616\n",
      "Iteration 39, loss = 301516.68718564\n",
      "Iteration 40, loss = 303597.72112862\n",
      "Iteration 41, loss = 293468.00061518\n",
      "Iteration 42, loss = 292152.91392763\n",
      "Iteration 43, loss = 290576.39662823\n",
      "Iteration 44, loss = 289508.06310624\n",
      "Iteration 45, loss = 294108.26478626\n",
      "Iteration 46, loss = 290973.16936266\n",
      "Iteration 47, loss = 292825.06953693\n",
      "Iteration 48, loss = 291014.33116834\n",
      "Iteration 49, loss = 285365.92226133\n",
      "Iteration 50, loss = 285828.60924704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2764690.39680945\n",
      "Iteration 2, loss = 2046297.04023148\n",
      "Iteration 3, loss = 1692928.50738722\n",
      "Iteration 4, loss = 1244063.06248989\n",
      "Iteration 5, loss = 852581.70627977\n",
      "Iteration 6, loss = 641202.06898953\n",
      "Iteration 7, loss = 593242.83149883\n",
      "Iteration 8, loss = 603614.61885958\n",
      "Iteration 9, loss = 569770.09200662\n",
      "Iteration 10, loss = 535581.94987159\n",
      "Iteration 11, loss = 531676.20726236\n",
      "Iteration 12, loss = 528286.52729796\n",
      "Iteration 13, loss = 486553.25823289\n",
      "Iteration 14, loss = 489407.62640604\n",
      "Iteration 15, loss = 482799.69461532\n",
      "Iteration 16, loss = 462671.84777214\n",
      "Iteration 17, loss = 455608.87393547\n",
      "Iteration 18, loss = 458724.73531344\n",
      "Iteration 19, loss = 449346.90296652\n",
      "Iteration 20, loss = 447290.51928920\n",
      "Iteration 21, loss = 423331.49840538\n",
      "Iteration 22, loss = 439127.73730325\n",
      "Iteration 23, loss = 429352.61086076\n",
      "Iteration 24, loss = 423021.45455178\n",
      "Iteration 25, loss = 440709.03477050\n",
      "Iteration 26, loss = 413953.59849584\n",
      "Iteration 27, loss = 420818.45970292\n",
      "Iteration 28, loss = 408854.54676111\n",
      "Iteration 29, loss = 405809.57920499\n",
      "Iteration 30, loss = 413735.75877314\n",
      "Iteration 31, loss = 396504.36309004\n",
      "Iteration 32, loss = 402832.80025075\n",
      "Iteration 33, loss = 404092.04223382\n",
      "Iteration 34, loss = 389234.01784205\n",
      "Iteration 35, loss = 400114.34199462\n",
      "Iteration 36, loss = 386238.89524339\n",
      "Iteration 37, loss = 395373.10637461\n",
      "Iteration 38, loss = 397643.78633265\n",
      "Iteration 39, loss = 397869.32306211\n",
      "Iteration 40, loss = 393293.38125749\n",
      "Iteration 41, loss = 387682.91700842\n",
      "Iteration 42, loss = 375899.85464947\n",
      "Iteration 43, loss = 382443.03679892\n",
      "Iteration 44, loss = 379773.16287414\n",
      "Iteration 45, loss = 377285.11569300\n",
      "Iteration 46, loss = 378707.51443252\n",
      "Iteration 47, loss = 377472.73583399\n",
      "Iteration 48, loss = 373851.54355762\n",
      "Iteration 49, loss = 375178.89448641\n",
      "Iteration 50, loss = 374729.05679160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2365722.95080141\n",
      "Iteration 2, loss = 1277285.65578748\n",
      "Iteration 3, loss = 915156.18690404\n",
      "Iteration 4, loss = 805985.11742538\n",
      "Iteration 5, loss = 708661.28597939\n",
      "Iteration 6, loss = 622725.33790311\n",
      "Iteration 7, loss = 578549.29853450\n",
      "Iteration 8, loss = 521814.31608494\n",
      "Iteration 9, loss = 494176.88696271\n",
      "Iteration 10, loss = 511092.84551580\n",
      "Iteration 11, loss = 478886.08504048\n",
      "Iteration 12, loss = 458690.44822175\n",
      "Iteration 13, loss = 457855.05629777\n",
      "Iteration 14, loss = 440692.16664134\n",
      "Iteration 15, loss = 416046.98981261\n",
      "Iteration 16, loss = 418442.60377386\n",
      "Iteration 17, loss = 395828.14626671\n",
      "Iteration 18, loss = 408678.27037704\n",
      "Iteration 19, loss = 403692.31738661\n",
      "Iteration 20, loss = 394607.30589497\n",
      "Iteration 21, loss = 382020.61899858\n",
      "Iteration 22, loss = 372295.03294968\n",
      "Iteration 23, loss = 368531.80186983\n",
      "Iteration 24, loss = 371083.35433834\n",
      "Iteration 25, loss = 359480.87244436\n",
      "Iteration 26, loss = 359629.77213847\n",
      "Iteration 27, loss = 354170.92404774\n",
      "Iteration 28, loss = 349389.49305630\n",
      "Iteration 29, loss = 346562.90568368\n",
      "Iteration 30, loss = 335587.31804629\n",
      "Iteration 31, loss = 345774.18742468\n",
      "Iteration 32, loss = 344897.51607063\n",
      "Iteration 33, loss = 337448.84958650\n",
      "Iteration 34, loss = 326408.39054474\n",
      "Iteration 35, loss = 321686.92108304\n",
      "Iteration 36, loss = 335427.13523476\n",
      "Iteration 37, loss = 315336.12906581\n",
      "Iteration 38, loss = 324219.60204186\n",
      "Iteration 39, loss = 319127.58571146\n",
      "Iteration 40, loss = 317731.15058703\n",
      "Iteration 41, loss = 324791.95744149\n",
      "Iteration 42, loss = 314694.82006801\n",
      "Iteration 43, loss = 314839.31058714\n",
      "Iteration 44, loss = 317851.98976702\n",
      "Iteration 45, loss = 306382.34537453\n",
      "Iteration 46, loss = 309784.36127451\n",
      "Iteration 47, loss = 306492.76297171\n",
      "Iteration 48, loss = 304544.72399638\n",
      "Iteration 49, loss = 308208.38826073\n",
      "Iteration 50, loss = 305626.57731740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2757072.53876207\n",
      "Iteration 2, loss = 1324547.60226858\n",
      "Iteration 3, loss = 899207.17775157\n",
      "Iteration 4, loss = 735944.65142949\n",
      "Iteration 5, loss = 633565.26386923\n",
      "Iteration 6, loss = 607146.48217597\n",
      "Iteration 7, loss = 544841.15280384\n",
      "Iteration 8, loss = 525287.71868075\n",
      "Iteration 9, loss = 487305.86651180\n",
      "Iteration 10, loss = 490767.32777988\n",
      "Iteration 11, loss = 470490.47397335\n",
      "Iteration 12, loss = 448303.07911560\n",
      "Iteration 13, loss = 451265.45936140\n",
      "Iteration 14, loss = 441047.78164643\n",
      "Iteration 15, loss = 413971.48323471\n",
      "Iteration 16, loss = 416713.98254289\n",
      "Iteration 17, loss = 392973.45623691\n",
      "Iteration 18, loss = 395664.32277656\n",
      "Iteration 19, loss = 398560.09652926\n",
      "Iteration 20, loss = 377033.38187154\n",
      "Iteration 21, loss = 375975.91094687\n",
      "Iteration 22, loss = 377821.71028412\n",
      "Iteration 23, loss = 358029.96904127\n",
      "Iteration 24, loss = 362020.56656914\n",
      "Iteration 25, loss = 361579.82532970\n",
      "Iteration 26, loss = 356604.89936950\n",
      "Iteration 27, loss = 348073.83204723\n",
      "Iteration 28, loss = 348840.45961984\n",
      "Iteration 29, loss = 347534.88991257\n",
      "Iteration 30, loss = 338779.65522845\n",
      "Iteration 31, loss = 338945.80933336\n",
      "Iteration 32, loss = 331494.37223756\n",
      "Iteration 33, loss = 339197.05119846\n",
      "Iteration 34, loss = 328423.15368225\n",
      "Iteration 35, loss = 328200.76555115\n",
      "Iteration 36, loss = 319970.11652993\n",
      "Iteration 37, loss = 325539.76498351\n",
      "Iteration 38, loss = 327817.39630467\n",
      "Iteration 39, loss = 319337.02889800\n",
      "Iteration 40, loss = 324619.08000279\n",
      "Iteration 41, loss = 314627.65654228\n",
      "Iteration 42, loss = 311637.18180930\n",
      "Iteration 43, loss = 308294.32663531\n",
      "Iteration 44, loss = 306203.34094706\n",
      "Iteration 45, loss = 310946.63793477\n",
      "Iteration 46, loss = 298673.78780255\n",
      "Iteration 47, loss = 312376.18929216\n",
      "Iteration 48, loss = 298870.81358999\n",
      "Iteration 49, loss = 306677.87877315\n",
      "Iteration 50, loss = 313609.47804139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2646011.56094805\n",
      "Iteration 2, loss = 1259746.52254208\n",
      "Iteration 3, loss = 901329.84970594\n",
      "Iteration 4, loss = 769510.29253113\n",
      "Iteration 5, loss = 687899.12195724\n",
      "Iteration 6, loss = 622904.83441394\n",
      "Iteration 7, loss = 570071.61705797\n",
      "Iteration 8, loss = 616208.84600082\n",
      "Iteration 9, loss = 559603.54594000\n",
      "Iteration 10, loss = 519152.98366081\n",
      "Iteration 11, loss = 505001.21676670\n",
      "Iteration 12, loss = 471994.39169112\n",
      "Iteration 13, loss = 471081.30101465\n",
      "Iteration 14, loss = 469501.89239362\n",
      "Iteration 15, loss = 442306.78116336\n",
      "Iteration 16, loss = 446817.70600731\n",
      "Iteration 17, loss = 418747.82135159\n",
      "Iteration 18, loss = 417975.77518454\n",
      "Iteration 19, loss = 409400.91655888\n",
      "Iteration 20, loss = 399986.45513121\n",
      "Iteration 21, loss = 388260.20240907\n",
      "Iteration 22, loss = 385429.72615743\n",
      "Iteration 23, loss = 383502.83085110\n",
      "Iteration 24, loss = 378151.51897415\n",
      "Iteration 25, loss = 368706.11360155\n",
      "Iteration 26, loss = 361540.46050870\n",
      "Iteration 27, loss = 367112.68958237\n",
      "Iteration 28, loss = 342869.04578858\n",
      "Iteration 29, loss = 343992.48620142\n",
      "Iteration 30, loss = 351499.63829159\n",
      "Iteration 31, loss = 341173.05411643\n",
      "Iteration 32, loss = 344476.26990247\n",
      "Iteration 33, loss = 340070.00716936\n",
      "Iteration 34, loss = 342376.63065721\n",
      "Iteration 35, loss = 334764.72201829\n",
      "Iteration 36, loss = 328204.35257466\n",
      "Iteration 37, loss = 326597.88204299\n",
      "Iteration 38, loss = 332534.90194209\n",
      "Iteration 39, loss = 324296.05569079\n",
      "Iteration 40, loss = 321674.33805362\n",
      "Iteration 41, loss = 319158.12630071\n",
      "Iteration 42, loss = 313899.74442302\n",
      "Iteration 43, loss = 316586.25138055\n",
      "Iteration 44, loss = 319563.88549554\n",
      "Iteration 45, loss = 310947.04519810\n",
      "Iteration 46, loss = 303686.19461310\n",
      "Iteration 47, loss = 298574.82820994\n",
      "Iteration 48, loss = 310984.55391216\n",
      "Iteration 49, loss = 311151.29940053\n",
      "Iteration 50, loss = 301031.91323242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2795045.14989763\n",
      "Iteration 2, loss = 1287506.66954523\n",
      "Iteration 3, loss = 945980.92470627\n",
      "Iteration 4, loss = 787469.81880063\n",
      "Iteration 5, loss = 692262.29599553\n",
      "Iteration 6, loss = 601323.55753278\n",
      "Iteration 7, loss = 608262.06170372\n",
      "Iteration 8, loss = 562719.74175480\n",
      "Iteration 9, loss = 531801.86503177\n",
      "Iteration 10, loss = 512025.99907903\n",
      "Iteration 11, loss = 494905.49736711\n",
      "Iteration 12, loss = 477408.07990463\n",
      "Iteration 13, loss = 451633.93057265\n",
      "Iteration 14, loss = 443488.84421012\n",
      "Iteration 15, loss = 424903.86771247\n",
      "Iteration 16, loss = 433315.52901173\n",
      "Iteration 17, loss = 415830.73492386\n",
      "Iteration 18, loss = 408115.71625478\n",
      "Iteration 19, loss = 402065.61085169\n",
      "Iteration 20, loss = 398297.05088466\n",
      "Iteration 21, loss = 394816.36036444\n",
      "Iteration 22, loss = 382884.75548615\n",
      "Iteration 23, loss = 378762.99220432\n",
      "Iteration 24, loss = 374418.51824056\n",
      "Iteration 25, loss = 369326.65507802\n",
      "Iteration 26, loss = 355080.26879643\n",
      "Iteration 27, loss = 356063.60007063\n",
      "Iteration 28, loss = 354619.43983569\n",
      "Iteration 29, loss = 346855.07517351\n",
      "Iteration 30, loss = 349783.86791368\n",
      "Iteration 31, loss = 349205.30765053\n",
      "Iteration 32, loss = 334932.77619056\n",
      "Iteration 33, loss = 333204.63055464\n",
      "Iteration 34, loss = 333647.96699616\n",
      "Iteration 35, loss = 320926.36971197\n",
      "Iteration 36, loss = 323835.42354196\n",
      "Iteration 37, loss = 325940.01007934\n",
      "Iteration 38, loss = 332650.29769363\n",
      "Iteration 39, loss = 324254.77816122\n",
      "Iteration 40, loss = 321906.50372706\n",
      "Iteration 41, loss = 322195.74846351\n",
      "Iteration 42, loss = 319293.65224474\n",
      "Iteration 43, loss = 318197.93563355\n",
      "Iteration 44, loss = 314306.46233291\n",
      "Iteration 45, loss = 306926.49087031\n",
      "Iteration 46, loss = 313544.12774919\n",
      "Iteration 47, loss = 306542.04049824\n",
      "Iteration 48, loss = 309114.29801415\n",
      "Iteration 49, loss = 299323.43002448\n",
      "Iteration 50, loss = 309310.40470904\n",
      "\n",
      "#### MLPRegressor ####\n",
      "score :0.9450\n",
      "[0.92923365 0.94585748 0.90526505 0.94181661 0.94728252]\n",
      "\n",
      "MSE    : 402490.97 \n",
      "MAE    : 410.69 \n",
      "RMSE   : 634.42 \n",
      "R2     : 0.95 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 19.0min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Test score</th>\n",
       "      <th>CV Train score (mean)</th>\n",
       "      <th>%%SVGean Squared error</th>\n",
       "      <th>Mean Absolute error</th>\n",
       "      <th>Root Mean Squared error</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.861113</td>\n",
       "      <td>0.860804</td>\n",
       "      <td>1.016588e+06</td>\n",
       "      <td>627.898926</td>\n",
       "      <td>1008.259885</td>\n",
       "      <td>0.861113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.999729</td>\n",
       "      <td>1.438553e+03</td>\n",
       "      <td>6.742476</td>\n",
       "      <td>37.928255</td>\n",
       "      <td>0.999803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.994694</td>\n",
       "      <td>0.989341</td>\n",
       "      <td>3.883563e+04</td>\n",
       "      <td>25.943104</td>\n",
       "      <td>197.067574</td>\n",
       "      <td>0.994694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>0.945011</td>\n",
       "      <td>0.933891</td>\n",
       "      <td>4.024910e+05</td>\n",
       "      <td>410.694273</td>\n",
       "      <td>634.421764</td>\n",
       "      <td>0.945011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  CV Test score  ...  Root Mean Squared error  R2 Score\n",
       "0       LinearRegression       0.861113  ...              1008.259885  0.861113\n",
       "1  RandomForestRegressor       0.999803  ...                37.928255  0.999803\n",
       "2    KNeighborsRegressor       0.994694  ...               197.067574  0.994694\n",
       "3           MLPRegressor       0.945011  ...               634.421764  0.945011\n",
       "\n",
       "[4 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd# Aprendizado de Comitês\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "df_diamonds = pd.read_csv('datasets/diamonds.csv')\n",
    "df_diamonds[df_diamonds.duplicated()].info()\n",
    "\n",
    "df_number_type = df_diamonds.select_dtypes(exclude='O').columns[1:]\n",
    "\n",
    "def range_for_remove_outliers(attr):\n",
    "    df_attr = df_diamonds[attr]\n",
    "    q3 = df_attr.quantile(q=0.75)\n",
    "    q1 = df_attr.quantile(q=0.25)\n",
    "\n",
    "    IQR  = q3 - q1\n",
    "    min_IQR = q1 - 1.5 * IQR\n",
    "    max_IQR = q3 + 1.5 * IQR\n",
    "    \n",
    "    return (min_IQR,max_IQR)\n",
    "\n",
    "def remove_outlier(df_in, col_name):\n",
    "    range_iqr = range_for_remove_outliers(col_name)\n",
    "    df_out = df_in[~((df_in < range_iqr[0]) |(df_in > range_iqr[1])).any(axis=1)]\n",
    "    return df_out\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd# Aprendizado de Comitês\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "df_diamonds_ro = remove_outlier(df_diamonds.select_dtypes(exclude='O'),df_number_type)\n",
    "\n",
    "y=df_diamonds_ro['price']\n",
    "X=df_diamonds_ro.drop('price', axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=0.2, random_state=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sc=StandardScaler()\n",
    "X_train_tx=sc.fit_transform(X_train)\n",
    "X_test_tx=sc.transform(X_test)\n",
    "\n",
    "dataset_1=(X_train, X_test, y_train, y_test, 'dataset_1')\n",
    "\n",
    "# Blank lists for all the details\n",
    "model_=[]\n",
    "cv_score_test=[]\n",
    "cv_score_train=[]\n",
    "mse_=[]\n",
    "mae_=[]\n",
    "rmse_=[]\n",
    "r2_=[]\n",
    "\n",
    "\n",
    "def run_model(model, dataset, modelname):\n",
    "    model.fit(dataset[0], dataset[2])\n",
    "    accuracies=cross_val_score(estimator=model, X=dataset[0], y=dataset[2], cv=5, verbose=1)\n",
    "    y_pred=model.predict(dataset[1])\n",
    "    print('')\n",
    "    score_1=model.score(dataset[1], dataset[3])\n",
    "    print(f'#### {modelname} ####')\n",
    "    print(\"score :%.4f\" %score_1)\n",
    "    print(accuracies)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(dataset[3], y_pred)\n",
    "    mae=mean_absolute_error(dataset[3], y_pred)\n",
    "    rmse=mean_squared_error(dataset[3], y_pred)**0.5\n",
    "    r2=r2_score(dataset[3], y_pred)\n",
    "   \n",
    "    \n",
    "    print('')\n",
    "    print('MSE    : %0.2f ' % mse)\n",
    "    print('MAE    : %0.2f ' % mae)\n",
    "    print('RMSE   : %0.2f ' % rmse)\n",
    "    print('R2     : %0.2f ' % r2)\n",
    "    \n",
    "    ## appending to the lists\n",
    "    \n",
    "    model_.append(modelname)\n",
    "    cv_score_test.append(score_1)\n",
    "    cv_score_train.append(np.mean(accuracies))\n",
    "    mse_.append(mse)\n",
    "    mae_.append(mae)\n",
    "    rmse_.append(rmse)\n",
    "    r2_.append(r2)\n",
    "\n",
    "\n",
    "model_dict={'LinearRegression': LinearRegression(),\n",
    "           'RandomForestRegressor': RandomForestRegressor(), \n",
    "            'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "            'MLPRegressor': MLPRegressor(hidden_layer_sizes=(100,), batch_size=2, learning_rate_init=0.01, learning_rate=\"adaptive\", max_iter=50, verbose=True)\n",
    "           }\n",
    "\n",
    "for models in model_dict:\n",
    "    run_model(model_dict[models], dataset_1, models)\n",
    "\n",
    "accuracy_data=pd.DataFrame(zip(model_, cv_score_test, cv_score_train, mse_, mae_, rmse_, r2_), columns=['Model', 'CV Test score', 'CV Train score (mean)', '%%SVGean Squared error', 'Mean Absolute error', 'Root Mean Squared error', 'R2 Score'])\n",
    "\n",
    "accuracy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm9XuCfwrkss"
   },
   "source": [
    "# Sem Outiliers Sem Normalizacao com unamed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iAFrOGp2rp9u",
    "outputId": "750a17f3-6d91-434c-e7fc-e00122034886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 0 entries\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  0 non-null      int64  \n",
      " 1   carat       0 non-null      float64\n",
      " 2   cut         0 non-null      object \n",
      " 3   color       0 non-null      object \n",
      " 4   clarity     0 non-null      object \n",
      " 5   depth       0 non-null      float64\n",
      " 6   table       0 non-null      float64\n",
      " 7   price       0 non-null      int64  \n",
      " 8   x           0 non-null      float64\n",
      " 9   y           0 non-null      float64\n",
      " 10  z           0 non-null      float64\n",
      "dtypes: float64(6), int64(2), object(3)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### LinearRegression ####\n",
      "score :0.8581\n",
      "[0.85858014 0.86393974 0.8667698  0.86217502 0.86096177]\n",
      "\n",
      "MSE    : 1070377.70 \n",
      "MAE    : 640.04 \n",
      "RMSE   : 1034.59 \n",
      "R2     : 0.86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   54.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### RandomForestRegressor ####\n",
      "score :0.9997\n",
      "[0.99959852 0.99970951 0.99966511 0.99969875 0.99983903]\n",
      "\n",
      "MSE    : 2003.03 \n",
      "MAE    : 7.78 \n",
      "RMSE   : 44.76 \n",
      "R2     : 1.00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### KNeighborsRegressor ####\n",
      "score :0.9833\n",
      "[0.98182618 0.98028807 0.98095504 0.981171   0.98146339]\n",
      "\n",
      "MSE    : 126323.01 \n",
      "MAE    : 175.56 \n",
      "RMSE   : 355.42 \n",
      "R2     : 0.98 \n",
      "Iteration 1, loss = 582617.36229947\n",
      "Iteration 2, loss = 235122.20620455\n",
      "Iteration 3, loss = 121126.34033815\n",
      "Iteration 4, loss = 71000.94079965\n",
      "Iteration 5, loss = 49190.05782004\n",
      "Iteration 6, loss = 38222.98974114\n",
      "Iteration 7, loss = 32069.70406567\n",
      "Iteration 8, loss = 27724.29178748\n",
      "Iteration 9, loss = 24904.95614597\n",
      "Iteration 10, loss = 22449.62394702\n",
      "Iteration 11, loss = 20695.79495180\n",
      "Iteration 12, loss = 19383.22106998\n",
      "Iteration 13, loss = 18454.09385542\n",
      "Iteration 14, loss = 17662.69109599\n",
      "Iteration 15, loss = 16943.09710633\n",
      "Iteration 16, loss = 16376.71835179\n",
      "Iteration 17, loss = 15787.34305042\n",
      "Iteration 18, loss = 15149.95455610\n",
      "Iteration 19, loss = 14317.62872724\n",
      "Iteration 20, loss = 13432.67967907\n",
      "Iteration 21, loss = 12766.24016611\n",
      "Iteration 22, loss = 12078.34529645\n",
      "Iteration 23, loss = 11315.52756281\n",
      "Iteration 24, loss = 10011.96653396\n",
      "Iteration 25, loss = 8683.52433797\n",
      "Iteration 26, loss = 8121.38491163\n",
      "Iteration 27, loss = 7735.70311232\n",
      "Iteration 28, loss = 7473.28490178\n",
      "Iteration 29, loss = 7392.04518566\n",
      "Iteration 30, loss = 7138.84508727\n",
      "Iteration 31, loss = 7123.06644606\n",
      "Iteration 32, loss = 6931.47472619\n",
      "Iteration 33, loss = 6892.12979847\n",
      "Iteration 34, loss = 6890.36771033\n",
      "Iteration 35, loss = 6758.95200823\n",
      "Iteration 36, loss = 6667.06221084\n",
      "Iteration 37, loss = 6590.02854367\n",
      "Iteration 38, loss = 6295.62634166\n",
      "Iteration 39, loss = 6517.15442659\n",
      "Iteration 40, loss = 6288.55989687\n",
      "Iteration 41, loss = 6350.69534883\n",
      "Iteration 42, loss = 6171.49635638\n",
      "Iteration 43, loss = 6298.81756639\n",
      "Iteration 44, loss = 6178.55270408\n",
      "Iteration 45, loss = 6183.18669598\n",
      "Iteration 46, loss = 6128.44406134\n",
      "Iteration 47, loss = 6105.01525109\n",
      "Iteration 48, loss = 6012.24440552\n",
      "Iteration 49, loss = 5960.32822133\n",
      "Iteration 50, loss = 5898.29247466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 606566.65173766\n",
      "Iteration 2, loss = 271932.60111188\n",
      "Iteration 3, loss = 183478.59974821\n",
      "Iteration 4, loss = 121352.14303405\n",
      "Iteration 5, loss = 76724.79270864\n",
      "Iteration 6, loss = 55573.17232375\n",
      "Iteration 7, loss = 44053.93911281\n",
      "Iteration 8, loss = 37962.90011930\n",
      "Iteration 9, loss = 33661.71534586\n",
      "Iteration 10, loss = 30682.47730035\n",
      "Iteration 11, loss = 27468.43302548\n",
      "Iteration 12, loss = 24390.76612340\n",
      "Iteration 13, loss = 22391.73821358\n",
      "Iteration 14, loss = 20765.64127097\n",
      "Iteration 15, loss = 19260.58903076\n",
      "Iteration 16, loss = 18015.14856319\n",
      "Iteration 17, loss = 16705.08827685\n",
      "Iteration 18, loss = 15736.26301826\n",
      "Iteration 19, loss = 14602.30184390\n",
      "Iteration 20, loss = 13793.73395576\n",
      "Iteration 21, loss = 13023.79800468\n",
      "Iteration 22, loss = 12166.49660530\n",
      "Iteration 23, loss = 11002.82744521\n",
      "Iteration 24, loss = 9859.58073493\n",
      "Iteration 25, loss = 9055.05636683\n",
      "Iteration 26, loss = 8534.27579698\n",
      "Iteration 27, loss = 8267.55726144\n",
      "Iteration 28, loss = 7815.81066157\n",
      "Iteration 29, loss = 7585.76168930\n",
      "Iteration 30, loss = 7509.25356433\n",
      "Iteration 31, loss = 7341.90671267\n",
      "Iteration 32, loss = 7149.61014750\n",
      "Iteration 33, loss = 7085.85436451\n",
      "Iteration 34, loss = 6978.20080852\n",
      "Iteration 35, loss = 6985.24441949\n",
      "Iteration 36, loss = 6621.60972033\n",
      "Iteration 37, loss = 6739.08735958\n",
      "Iteration 38, loss = 6645.92868914\n",
      "Iteration 39, loss = 6508.97812944\n",
      "Iteration 40, loss = 6251.97395898\n",
      "Iteration 41, loss = 6243.09697391\n",
      "Iteration 42, loss = 6158.41536599\n",
      "Iteration 43, loss = 5967.30912647\n",
      "Iteration 44, loss = 5970.90164640\n",
      "Iteration 45, loss = 5751.71167848\n",
      "Iteration 46, loss = 5850.36543794\n",
      "Iteration 47, loss = 5727.02182644\n",
      "Iteration 48, loss = 5705.52485024\n",
      "Iteration 49, loss = 5659.95600050\n",
      "Iteration 50, loss = 5440.00761337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 629562.68744601\n",
      "Iteration 2, loss = 245022.49181065\n",
      "Iteration 3, loss = 142330.96071865\n",
      "Iteration 4, loss = 88975.61334203\n",
      "Iteration 5, loss = 58606.49305302\n",
      "Iteration 6, loss = 44605.13536009\n",
      "Iteration 7, loss = 37169.98665376\n",
      "Iteration 8, loss = 32308.28282087\n",
      "Iteration 9, loss = 28186.55203039\n",
      "Iteration 10, loss = 24950.70726440\n",
      "Iteration 11, loss = 22618.99625038\n",
      "Iteration 12, loss = 20890.00338627\n",
      "Iteration 13, loss = 19535.69364940\n",
      "Iteration 14, loss = 18295.56290518\n",
      "Iteration 15, loss = 17833.64909009\n",
      "Iteration 16, loss = 16898.42454883\n",
      "Iteration 17, loss = 16652.03759369\n",
      "Iteration 18, loss = 15977.45555313\n",
      "Iteration 19, loss = 15830.55078391\n",
      "Iteration 20, loss = 15353.74488930\n",
      "Iteration 21, loss = 14883.27176263\n",
      "Iteration 22, loss = 14647.73835369\n",
      "Iteration 23, loss = 14411.16491785\n",
      "Iteration 24, loss = 14246.05014964\n",
      "Iteration 25, loss = 14262.71438558\n",
      "Iteration 26, loss = 13926.48512575\n",
      "Iteration 27, loss = 13756.90048091\n",
      "Iteration 28, loss = 13583.58994592\n",
      "Iteration 29, loss = 13669.10218932\n",
      "Iteration 30, loss = 13370.68743955\n",
      "Iteration 31, loss = 13356.13671272\n",
      "Iteration 32, loss = 13270.22541392\n",
      "Iteration 33, loss = 13057.35877686\n",
      "Iteration 34, loss = 12963.01334858\n",
      "Iteration 35, loss = 12825.23798093\n",
      "Iteration 36, loss = 12739.35876249\n",
      "Iteration 37, loss = 12689.86863022\n",
      "Iteration 38, loss = 12496.54098140\n",
      "Iteration 39, loss = 12569.44110327\n",
      "Iteration 40, loss = 12275.80077554\n",
      "Iteration 41, loss = 12182.44989585\n",
      "Iteration 42, loss = 12225.20720992\n",
      "Iteration 43, loss = 12284.57689068\n",
      "Iteration 44, loss = 12005.63567242\n",
      "Iteration 45, loss = 12069.89442514\n",
      "Iteration 46, loss = 11951.54104205\n",
      "Iteration 47, loss = 11870.34600574\n",
      "Iteration 48, loss = 11935.55143086\n",
      "Iteration 49, loss = 11665.93393770\n",
      "Iteration 50, loss = 11880.62609769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 635982.56631615\n",
      "Iteration 2, loss = 310064.30552500\n",
      "Iteration 3, loss = 210155.54189686\n",
      "Iteration 4, loss = 134832.52890343\n",
      "Iteration 5, loss = 92140.76744570\n",
      "Iteration 6, loss = 67766.67917926\n",
      "Iteration 7, loss = 52034.96123689\n",
      "Iteration 8, loss = 41767.53110216\n",
      "Iteration 9, loss = 35499.14773059\n",
      "Iteration 10, loss = 30670.46141974\n",
      "Iteration 11, loss = 27343.15876568\n",
      "Iteration 12, loss = 24836.54365995\n",
      "Iteration 13, loss = 22599.26177251\n",
      "Iteration 14, loss = 21018.47457896\n",
      "Iteration 15, loss = 19730.55465962\n",
      "Iteration 16, loss = 18784.27820086\n",
      "Iteration 17, loss = 17816.48115995\n",
      "Iteration 18, loss = 17106.75308755\n",
      "Iteration 19, loss = 16501.33751707\n",
      "Iteration 20, loss = 15772.54918563\n",
      "Iteration 21, loss = 15339.41289731\n",
      "Iteration 22, loss = 14553.19594758\n",
      "Iteration 23, loss = 13310.00710825\n",
      "Iteration 24, loss = 12300.12669584\n",
      "Iteration 25, loss = 11503.25089285\n",
      "Iteration 26, loss = 10487.78676027\n",
      "Iteration 27, loss = 9725.68336473\n",
      "Iteration 28, loss = 9202.44049437\n",
      "Iteration 29, loss = 8389.64319966\n",
      "Iteration 30, loss = 7976.38169267\n",
      "Iteration 31, loss = 7862.30996015\n",
      "Iteration 32, loss = 7596.93721610\n",
      "Iteration 33, loss = 7465.16354253\n",
      "Iteration 34, loss = 7437.34594336\n",
      "Iteration 35, loss = 7193.86110778\n",
      "Iteration 36, loss = 7124.38769882\n",
      "Iteration 37, loss = 7055.07977915\n",
      "Iteration 38, loss = 6873.70054402\n",
      "Iteration 39, loss = 6856.42900137\n",
      "Iteration 40, loss = 6724.48738235\n",
      "Iteration 41, loss = 6579.47543922\n",
      "Iteration 42, loss = 6482.20535303\n",
      "Iteration 43, loss = 6381.16122703\n",
      "Iteration 44, loss = 6277.63238260\n",
      "Iteration 45, loss = 6113.46864267\n",
      "Iteration 46, loss = 6120.69561729\n",
      "Iteration 47, loss = 5986.73988249\n",
      "Iteration 48, loss = 5832.46987497\n",
      "Iteration 49, loss = 5821.38567370\n",
      "Iteration 50, loss = 5652.42986408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 578985.92769625\n",
      "Iteration 2, loss = 218287.75822927\n",
      "Iteration 3, loss = 128658.81739208\n",
      "Iteration 4, loss = 84436.88716569\n",
      "Iteration 5, loss = 61648.00141677\n",
      "Iteration 6, loss = 48724.14060190\n",
      "Iteration 7, loss = 40811.28711252\n",
      "Iteration 8, loss = 35567.78360976\n",
      "Iteration 9, loss = 30822.77279201\n",
      "Iteration 10, loss = 26571.80854981\n",
      "Iteration 11, loss = 22871.59908029\n",
      "Iteration 12, loss = 20532.78077389\n",
      "Iteration 13, loss = 17572.19018621\n",
      "Iteration 14, loss = 15123.40864274\n",
      "Iteration 15, loss = 13493.89051190\n",
      "Iteration 16, loss = 12036.94510396\n",
      "Iteration 17, loss = 11283.98892786\n",
      "Iteration 18, loss = 10546.46437757\n",
      "Iteration 19, loss = 9743.83638925\n",
      "Iteration 20, loss = 9416.01900311\n",
      "Iteration 21, loss = 8955.86819087\n",
      "Iteration 22, loss = 8557.03007860\n",
      "Iteration 23, loss = 8489.02565496\n",
      "Iteration 24, loss = 8220.49240573\n",
      "Iteration 25, loss = 8035.61526610\n",
      "Iteration 26, loss = 8094.01807574\n",
      "Iteration 27, loss = 7849.96406487\n",
      "Iteration 28, loss = 7744.17976719\n",
      "Iteration 29, loss = 7471.45937791\n",
      "Iteration 30, loss = 7556.60792767\n",
      "Iteration 31, loss = 7386.55177958\n",
      "Iteration 32, loss = 7532.77144189\n",
      "Iteration 33, loss = 7414.74330258\n",
      "Iteration 34, loss = 7398.16796989\n",
      "Iteration 35, loss = 7189.60768962\n",
      "Iteration 36, loss = 7513.95107281\n",
      "Iteration 37, loss = 7127.31724441\n",
      "Iteration 38, loss = 7065.80890253\n",
      "Iteration 39, loss = 7133.48920025\n",
      "Iteration 40, loss = 7061.02154908\n",
      "Iteration 41, loss = 7087.37725508\n",
      "Iteration 42, loss = 7005.05425646\n",
      "Iteration 43, loss = 6983.57677923\n",
      "Iteration 44, loss = 6933.01610646\n",
      "Iteration 45, loss = 7012.62101243\n",
      "Iteration 46, loss = 6864.75330670\n",
      "Iteration 47, loss = 6885.97915265\n",
      "Iteration 48, loss = 6808.32551219\n",
      "Iteration 49, loss = 6839.26404933\n",
      "Iteration 50, loss = 6832.29307990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 628697.89010385\n",
      "Iteration 2, loss = 275067.05772427\n",
      "Iteration 3, loss = 164682.74801364\n",
      "Iteration 4, loss = 110939.65527119\n",
      "Iteration 5, loss = 78745.37246868\n",
      "Iteration 6, loss = 56347.79132812\n",
      "Iteration 7, loss = 43628.22923449\n",
      "Iteration 8, loss = 36239.66365717\n",
      "Iteration 9, loss = 31177.32998612\n",
      "Iteration 10, loss = 27463.73551864\n",
      "Iteration 11, loss = 24635.23306408\n",
      "Iteration 12, loss = 22365.54824532\n",
      "Iteration 13, loss = 20517.83389178\n",
      "Iteration 14, loss = 19366.60910974\n",
      "Iteration 15, loss = 18220.17365239\n",
      "Iteration 16, loss = 17288.31413301\n",
      "Iteration 17, loss = 16685.49805731\n",
      "Iteration 18, loss = 16237.79778185\n",
      "Iteration 19, loss = 15744.49075587\n",
      "Iteration 20, loss = 15528.66459945\n",
      "Iteration 21, loss = 15282.63421802\n",
      "Iteration 22, loss = 15108.00201303\n",
      "Iteration 23, loss = 14852.13222606\n",
      "Iteration 24, loss = 14451.16985574\n",
      "Iteration 25, loss = 14498.76200502\n",
      "Iteration 26, loss = 14339.88903194\n",
      "Iteration 27, loss = 14183.00962376\n",
      "Iteration 28, loss = 14214.44201310\n",
      "Iteration 29, loss = 14014.12118894\n",
      "Iteration 30, loss = 14126.97747640\n",
      "Iteration 31, loss = 13892.78179762\n",
      "Iteration 32, loss = 13795.57989157\n",
      "Iteration 33, loss = 13619.78343848\n",
      "Iteration 34, loss = 13486.63361424\n",
      "Iteration 35, loss = 13691.82949145\n",
      "Iteration 36, loss = 13518.33671744\n",
      "Iteration 37, loss = 13697.76898369\n",
      "Iteration 38, loss = 13451.31952638\n",
      "Iteration 39, loss = 13376.06777978\n",
      "Iteration 40, loss = 13378.45796652\n",
      "Iteration 41, loss = 13278.04179206\n",
      "Iteration 42, loss = 13292.42438335\n",
      "Iteration 43, loss = 13049.66689457\n",
      "Iteration 44, loss = 13192.31038808\n",
      "Iteration 45, loss = 13045.22316285\n",
      "Iteration 46, loss = 13046.17079046\n",
      "Iteration 47, loss = 12996.67317571\n",
      "Iteration 48, loss = 12955.34868940\n",
      "Iteration 49, loss = 12957.92209731\n",
      "Iteration 50, loss = 12817.27126185\n",
      "\n",
      "#### MLPRegressor ####\n",
      "score :0.9989\n",
      "[0.99865735 0.99650425 0.9987981  0.99894142 0.99702805]\n",
      "\n",
      "MSE    : 8040.86 \n",
      "MAE    : 46.28 \n",
      "RMSE   : 89.67 \n",
      "R2     : 1.00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 14.0min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Test score</th>\n",
       "      <th>CV Train score (mean)</th>\n",
       "      <th>%%SVGean Squared error</th>\n",
       "      <th>Mean Absolute error</th>\n",
       "      <th>Root Mean Squared error</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.858101</td>\n",
       "      <td>0.862485</td>\n",
       "      <td>1.070378e+06</td>\n",
       "      <td>640.042799</td>\n",
       "      <td>1034.590597</td>\n",
       "      <td>0.858101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.999702</td>\n",
       "      <td>2.003029e+03</td>\n",
       "      <td>7.775979</td>\n",
       "      <td>44.755215</td>\n",
       "      <td>0.999734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.983253</td>\n",
       "      <td>0.981141</td>\n",
       "      <td>1.263230e+05</td>\n",
       "      <td>175.562430</td>\n",
       "      <td>355.419488</td>\n",
       "      <td>0.983253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>0.998934</td>\n",
       "      <td>0.997986</td>\n",
       "      <td>8.040860e+03</td>\n",
       "      <td>46.283597</td>\n",
       "      <td>89.670842</td>\n",
       "      <td>0.998934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  CV Test score  ...  Root Mean Squared error  R2 Score\n",
       "0       LinearRegression       0.858101  ...              1034.590597  0.858101\n",
       "1  RandomForestRegressor       0.999734  ...                44.755215  0.999734\n",
       "2    KNeighborsRegressor       0.983253  ...               355.419488  0.983253\n",
       "3           MLPRegressor       0.998934  ...                89.670842  0.998934\n",
       "\n",
       "[4 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd# Aprendizado de Comitês\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "df_diamonds = pd.read_csv('datasets/diamonds.csv')\n",
    "df_diamonds[df_diamonds.duplicated()].info()\n",
    "\n",
    "df_number_type = df_diamonds.select_dtypes(exclude='O').columns[1:]\n",
    "\n",
    "\n",
    "def range_for_remove_outliers(attr):\n",
    "    df_attr = df_diamonds[attr]\n",
    "    q3 = df_attr.quantile(q=0.75)\n",
    "    q1 = df_attr.quantile(q=0.25)\n",
    "\n",
    "    IQR  = q3 - q1\n",
    "    min_IQR = q1 - 1.5 * IQR\n",
    "    max_IQR = q3 + 1.5 * IQR\n",
    "    \n",
    "    return (min_IQR,max_IQR)\n",
    "\n",
    "def remove_outlier(df_in, col_name):\n",
    "    range_iqr = range_for_remove_outliers(col_name)\n",
    "    df_out = df_in[~((df_in < range_iqr[0]) |(df_in > range_iqr[1])).any(axis=1)]\n",
    "    return df_out\n",
    "\n",
    "\n",
    "\n",
    "df_diamonds_ro = remove_outlier(df_diamonds.select_dtypes(exclude='O'),df_number_type)\n",
    "\n",
    "y=df_diamonds_ro['price']\n",
    "X=df_diamonds_ro.drop('price', axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=0.4, random_state=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "sc=StandardScaler()\n",
    "X_train_tx=sc.fit_transform(X_train)\n",
    "X_test_tx=sc.transform(X_test)\n",
    "\n",
    "\n",
    "dataset_1 = (X_train_tx, X_test_tx, y_train, y_test, 'dataset_1')\n",
    "\n",
    "# Blank lists for all the details\n",
    "model_=[]\n",
    "cv_score_test=[]\n",
    "cv_score_train=[]\n",
    "mse_=[]\n",
    "mae_=[]\n",
    "rmse_=[]\n",
    "r2_=[]\n",
    "\n",
    "def run_model(model, dataset, modelname):\n",
    "    model.fit(dataset[0], dataset[2])\n",
    "    accuracies=cross_val_score(estimator=model, X=dataset[0], y=dataset[2], cv=5, verbose=1)\n",
    "    y_pred=model.predict(dataset[1])\n",
    "    print('')\n",
    "    score_1=model.score(dataset[1], dataset[3])\n",
    "    print(f'#### {modelname} ####')\n",
    "    print(\"score :%.4f\" %score_1)\n",
    "    print(accuracies)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(dataset[3], y_pred)\n",
    "    mae=mean_absolute_error(dataset[3], y_pred)\n",
    "    rmse=mean_squared_error(dataset[3], y_pred)**0.5\n",
    "    r2=r2_score(dataset[3], y_pred)\n",
    "   \n",
    "    \n",
    "    print('')\n",
    "    print('MSE    : %0.2f ' % mse)\n",
    "    print('MAE    : %0.2f ' % mae)\n",
    "    print('RMSE   : %0.2f ' % rmse)\n",
    "    print('R2     : %0.2f ' % r2)\n",
    "    \n",
    "    ## appending to the lists\n",
    "    \n",
    "    model_.append(modelname)\n",
    "    cv_score_test.append(score_1)\n",
    "    cv_score_train.append(np.mean(accuracies))\n",
    "    mse_.append(mse)\n",
    "    mae_.append(mae)\n",
    "    rmse_.append(rmse)\n",
    "    r2_.append(r2)\n",
    "\n",
    "model_dict={'LinearRegression': LinearRegression(),\n",
    "            'RandomForestRegressor': RandomForestRegressor(), \n",
    "            'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "            'MLPRegressor': MLPRegressor(hidden_layer_sizes=(100,), batch_size=4, learning_rate_init=0.01, learning_rate=\"adaptive\", max_iter=100, verbose=True)\n",
    "\n",
    "\n",
    "           }\n",
    "\n",
    "for models in model_dict:\n",
    "    run_model(model_dict[models], dataset_1, models)\n",
    "\n",
    "accuracy_data=pd.DataFrame(zip(model_, cv_score_test, cv_score_train, mse_, mae_, rmse_, r2_), columns=['Model', 'CV Test score', 'CV Train score (mean)', '%%SVGean Squared error', 'Mean Absolute error', 'Root Mean Squared error', 'R2 Score'])\n",
    "accuracy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eprC8-3sATL"
   },
   "source": [
    "# Sem Outliers Sem Normalização sem unamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "N5uBy6pWssM-",
    "outputId": "7861af24-d1a9-467f-ef2f-dbabb5ad6d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 146 entries, 1005 to 52861\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   carat    146 non-null    float64\n",
      " 1   cut      146 non-null    object \n",
      " 2   color    146 non-null    object \n",
      " 3   clarity  146 non-null    object \n",
      " 4   depth    146 non-null    float64\n",
      " 5   table    146 non-null    float64\n",
      " 6   price    146 non-null    int64  \n",
      " 7   x        146 non-null    float64\n",
      " 8   y        146 non-null    float64\n",
      " 9   z        146 non-null    float64\n",
      "dtypes: float64(6), int64(1), object(3)\n",
      "memory usage: 12.5+ KB\n",
      "\n",
      "#### LinearRegression ####\n",
      "score :0.8555\n",
      "[0.85263266 0.86034477 0.85443187 0.85589875 0.85740044]\n",
      "\n",
      "MSE    : 1115112.97 \n",
      "MAE    : 660.71 \n",
      "RMSE   : 1055.99 \n",
      "R2     : 0.86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   47.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### RandomForestRegressor ####\n",
      "score :0.8689\n",
      "[0.86414463 0.86884806 0.86791363 0.86705533 0.86790236]\n",
      "\n",
      "MSE    : 1011974.66 \n",
      "MAE    : 601.92 \n",
      "RMSE   : 1005.97 \n",
      "R2     : 0.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### KNeighborsRegressor ####\n",
      "score :0.8597\n",
      "[0.85231662 0.85246521 0.85680284 0.86094611 0.85813115]\n",
      "\n",
      "MSE    : 1083059.11 \n",
      "MAE    : 621.76 \n",
      "RMSE   : 1040.70 \n",
      "R2     : 0.86 \n",
      "Iteration 1, loss = 924822.84811402\n",
      "Iteration 2, loss = 562479.21913532\n",
      "Iteration 3, loss = 555838.82349557\n",
      "Iteration 4, loss = 557459.22773548\n",
      "Iteration 5, loss = 550576.42717451\n",
      "Iteration 6, loss = 546701.48786027\n",
      "Iteration 7, loss = 545811.51224771\n",
      "Iteration 8, loss = 541832.93667117\n",
      "Iteration 9, loss = 538086.65839517\n",
      "Iteration 10, loss = 535261.14489121\n",
      "Iteration 11, loss = 530151.46726685\n",
      "Iteration 12, loss = 532457.26531419\n",
      "Iteration 13, loss = 531399.20087775\n",
      "Iteration 14, loss = 528042.35274880\n",
      "Iteration 15, loss = 528461.56361539\n",
      "Iteration 16, loss = 529291.92862227\n",
      "Iteration 17, loss = 527636.20033090\n",
      "Iteration 18, loss = 526721.91295509\n",
      "Iteration 19, loss = 524956.77875237\n",
      "Iteration 20, loss = 523335.00132622\n",
      "Iteration 21, loss = 524455.31163314\n",
      "Iteration 22, loss = 524809.12057631\n",
      "Iteration 23, loss = 523897.39148420\n",
      "Iteration 24, loss = 521510.53038409\n",
      "Iteration 25, loss = 523073.13250247\n",
      "Iteration 26, loss = 522227.03681408\n",
      "Iteration 27, loss = 522134.07753875\n",
      "Iteration 28, loss = 522005.93865609\n",
      "Iteration 29, loss = 520708.80793971\n",
      "Iteration 30, loss = 518875.93426691\n",
      "Iteration 31, loss = 520666.48718743\n",
      "Iteration 32, loss = 520015.58714296\n",
      "Iteration 33, loss = 519288.09265863\n",
      "Iteration 34, loss = 521426.18903328\n",
      "Iteration 35, loss = 517986.34866004\n",
      "Iteration 36, loss = 518496.38137644\n",
      "Iteration 37, loss = 519135.69915190\n",
      "Iteration 38, loss = 517616.71287640\n",
      "Iteration 39, loss = 517907.75653087\n",
      "Iteration 40, loss = 518194.00668818\n",
      "Iteration 41, loss = 516634.86966310\n",
      "Iteration 42, loss = 517256.92495089\n",
      "Iteration 43, loss = 518150.67128918\n",
      "Iteration 44, loss = 517176.16816662\n",
      "Iteration 45, loss = 518113.30427406\n",
      "Iteration 46, loss = 516000.41863468\n",
      "Iteration 47, loss = 514290.67635379\n",
      "Iteration 48, loss = 516156.26052975\n",
      "Iteration 49, loss = 515830.43985106\n",
      "Iteration 50, loss = 515703.29485137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1006478.00177991\n",
      "Iteration 2, loss = 559588.40064691\n",
      "Iteration 3, loss = 556293.25397300\n",
      "Iteration 4, loss = 553089.08199570\n",
      "Iteration 5, loss = 554832.75472966\n",
      "Iteration 6, loss = 548770.49908664\n",
      "Iteration 7, loss = 549478.13835990\n",
      "Iteration 8, loss = 544633.78685809\n",
      "Iteration 9, loss = 545171.52311899\n",
      "Iteration 10, loss = 542449.79593755\n",
      "Iteration 11, loss = 539374.48462403\n",
      "Iteration 12, loss = 539076.19456427\n",
      "Iteration 13, loss = 533019.34173466\n",
      "Iteration 14, loss = 532261.05707915\n",
      "Iteration 15, loss = 535948.60670531\n",
      "Iteration 16, loss = 532731.66164499\n",
      "Iteration 17, loss = 527949.07981652\n",
      "Iteration 18, loss = 532505.38062221\n",
      "Iteration 19, loss = 527820.46203109\n",
      "Iteration 20, loss = 529793.14468824\n",
      "Iteration 21, loss = 529323.73483505\n",
      "Iteration 22, loss = 525849.96939304\n",
      "Iteration 23, loss = 526462.42587001\n",
      "Iteration 24, loss = 525922.25632462\n",
      "Iteration 25, loss = 524917.36744201\n",
      "Iteration 26, loss = 528818.86336741\n",
      "Iteration 27, loss = 525600.03262663\n",
      "Iteration 28, loss = 524944.21669546\n",
      "Iteration 29, loss = 523000.82245121\n",
      "Iteration 30, loss = 524142.10877211\n",
      "Iteration 31, loss = 523027.71649034\n",
      "Iteration 32, loss = 523073.39994920\n",
      "Iteration 33, loss = 522627.53611028\n",
      "Iteration 34, loss = 521655.52291242\n",
      "Iteration 35, loss = 521251.60863937\n",
      "Iteration 36, loss = 521390.22302256\n",
      "Iteration 37, loss = 522900.46462936\n",
      "Iteration 38, loss = 522310.33916820\n",
      "Iteration 39, loss = 520852.57224702\n",
      "Iteration 40, loss = 520612.40217738\n",
      "Iteration 41, loss = 521419.01533610\n",
      "Iteration 42, loss = 520955.29324872\n",
      "Iteration 43, loss = 521061.19590510\n",
      "Iteration 44, loss = 519015.24288535\n",
      "Iteration 45, loss = 520156.23948134\n",
      "Iteration 46, loss = 518026.14168553\n",
      "Iteration 47, loss = 520115.71131775\n",
      "Iteration 48, loss = 520833.97791641\n",
      "Iteration 49, loss = 517523.61035977\n",
      "Iteration 50, loss = 518677.63572468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 985918.31540956\n",
      "Iteration 2, loss = 563624.14547787\n",
      "Iteration 3, loss = 562734.15985587\n",
      "Iteration 4, loss = 557067.75693980\n",
      "Iteration 5, loss = 558513.19415250\n",
      "Iteration 6, loss = 549283.16651416\n",
      "Iteration 7, loss = 554077.92708083\n",
      "Iteration 8, loss = 548595.94329484\n",
      "Iteration 9, loss = 542878.59112043\n",
      "Iteration 10, loss = 538827.12146689\n",
      "Iteration 11, loss = 535929.31808605\n",
      "Iteration 12, loss = 531408.83790545\n",
      "Iteration 13, loss = 534475.51705996\n",
      "Iteration 14, loss = 532633.63564140\n",
      "Iteration 15, loss = 529192.65009116\n",
      "Iteration 16, loss = 531227.41389810\n",
      "Iteration 17, loss = 531123.15028342\n",
      "Iteration 18, loss = 529018.22492818\n",
      "Iteration 19, loss = 526992.77879199\n",
      "Iteration 20, loss = 528345.31740216\n",
      "Iteration 21, loss = 526418.61163819\n",
      "Iteration 22, loss = 524286.45463710\n",
      "Iteration 23, loss = 527299.84980261\n",
      "Iteration 24, loss = 524068.21238887\n",
      "Iteration 25, loss = 522882.94899455\n",
      "Iteration 26, loss = 523805.23735603\n",
      "Iteration 27, loss = 521371.85535694\n",
      "Iteration 28, loss = 522298.54221604\n",
      "Iteration 29, loss = 521757.48344804\n",
      "Iteration 30, loss = 521603.94358027\n",
      "Iteration 31, loss = 524004.66991355\n",
      "Iteration 32, loss = 522966.04780593\n",
      "Iteration 33, loss = 520870.73530093\n",
      "Iteration 34, loss = 520574.04473508\n",
      "Iteration 35, loss = 519630.77166320\n",
      "Iteration 36, loss = 521634.22122339\n",
      "Iteration 37, loss = 517119.69209219\n",
      "Iteration 38, loss = 519414.83442123\n",
      "Iteration 39, loss = 516847.57614232\n",
      "Iteration 40, loss = 517997.63050009\n",
      "Iteration 41, loss = 518562.87236017\n",
      "Iteration 42, loss = 516758.43417538\n",
      "Iteration 43, loss = 517774.01712292\n",
      "Iteration 44, loss = 518005.54263504\n",
      "Iteration 45, loss = 518138.71716998\n",
      "Iteration 46, loss = 519099.56673307\n",
      "Iteration 47, loss = 518592.93585462\n",
      "Iteration 48, loss = 516347.57259104\n",
      "Iteration 49, loss = 516744.71026712\n",
      "Iteration 50, loss = 516733.02099019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 996956.52331558\n",
      "Iteration 2, loss = 562807.16210041\n",
      "Iteration 3, loss = 554915.62297808\n",
      "Iteration 4, loss = 556468.81810037\n",
      "Iteration 5, loss = 554884.15376945\n",
      "Iteration 6, loss = 548852.27745714\n",
      "Iteration 7, loss = 548908.77295554\n",
      "Iteration 8, loss = 545725.32149250\n",
      "Iteration 9, loss = 543417.16822726\n",
      "Iteration 10, loss = 537075.38597030\n",
      "Iteration 11, loss = 535017.26333657\n",
      "Iteration 12, loss = 534744.24718271\n",
      "Iteration 13, loss = 529698.91912887\n",
      "Iteration 14, loss = 527452.64242093\n",
      "Iteration 15, loss = 526124.01150934\n",
      "Iteration 16, loss = 528112.43838735\n",
      "Iteration 17, loss = 528878.82284193\n",
      "Iteration 18, loss = 525592.31753943\n",
      "Iteration 19, loss = 527921.01855917\n",
      "Iteration 20, loss = 523647.29609326\n",
      "Iteration 21, loss = 522844.30223133\n",
      "Iteration 22, loss = 524035.43022642\n",
      "Iteration 23, loss = 521987.15199599\n",
      "Iteration 24, loss = 523817.93996255\n",
      "Iteration 25, loss = 520859.76677008\n",
      "Iteration 26, loss = 520595.25769875\n",
      "Iteration 27, loss = 520138.04718824\n",
      "Iteration 28, loss = 519612.07065528\n",
      "Iteration 29, loss = 521889.69614510\n",
      "Iteration 30, loss = 518659.70114399\n",
      "Iteration 31, loss = 519047.69166526\n",
      "Iteration 32, loss = 518751.46586231\n",
      "Iteration 33, loss = 516826.28099452\n",
      "Iteration 34, loss = 517672.39819623\n",
      "Iteration 35, loss = 517787.29745931\n",
      "Iteration 36, loss = 518368.02595829\n",
      "Iteration 37, loss = 518255.26381891\n",
      "Iteration 38, loss = 516020.41176453\n",
      "Iteration 39, loss = 517012.29610620\n",
      "Iteration 40, loss = 517593.97398517\n",
      "Iteration 41, loss = 516468.23373892\n",
      "Iteration 42, loss = 517803.77950435\n",
      "Iteration 43, loss = 513770.63448718\n",
      "Iteration 44, loss = 513995.76811305\n",
      "Iteration 45, loss = 515076.91987495\n",
      "Iteration 46, loss = 514697.30256850\n",
      "Iteration 47, loss = 514227.66849794\n",
      "Iteration 48, loss = 514175.82894908\n",
      "Iteration 49, loss = 512394.12632680\n",
      "Iteration 50, loss = 512704.28192996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 959210.06761259\n",
      "Iteration 2, loss = 565473.36738487\n",
      "Iteration 3, loss = 558537.25212065\n",
      "Iteration 4, loss = 560448.58515387\n",
      "Iteration 5, loss = 561214.90927597\n",
      "Iteration 6, loss = 552280.03255197\n",
      "Iteration 7, loss = 551869.89822819\n",
      "Iteration 8, loss = 545916.69704352\n",
      "Iteration 9, loss = 539476.37889713\n",
      "Iteration 10, loss = 540838.67571633\n",
      "Iteration 11, loss = 533755.76264074\n",
      "Iteration 12, loss = 533718.92606315\n",
      "Iteration 13, loss = 533830.67281589\n",
      "Iteration 14, loss = 534320.65363116\n",
      "Iteration 15, loss = 535058.80487362\n",
      "Iteration 16, loss = 533703.62771727\n",
      "Iteration 17, loss = 528231.49587568\n",
      "Iteration 18, loss = 533207.29411041\n",
      "Iteration 19, loss = 530067.35572612\n",
      "Iteration 20, loss = 528579.20392322\n",
      "Iteration 21, loss = 528529.12175113\n",
      "Iteration 22, loss = 526643.61391459\n",
      "Iteration 23, loss = 526087.33816815\n",
      "Iteration 24, loss = 527302.74907156\n",
      "Iteration 25, loss = 527514.50595280\n",
      "Iteration 26, loss = 525410.61655198\n",
      "Iteration 27, loss = 526505.31628896\n",
      "Iteration 28, loss = 522943.34572537\n",
      "Iteration 29, loss = 524132.84593511\n",
      "Iteration 30, loss = 523921.16617285\n",
      "Iteration 31, loss = 522768.84407718\n",
      "Iteration 32, loss = 521210.16742547\n",
      "Iteration 33, loss = 521866.13559489\n",
      "Iteration 34, loss = 522416.74047908\n",
      "Iteration 35, loss = 521601.30675499\n",
      "Iteration 36, loss = 523989.79638096\n",
      "Iteration 37, loss = 520601.10884572\n",
      "Iteration 38, loss = 522148.50058441\n",
      "Iteration 39, loss = 521508.29654730\n",
      "Iteration 40, loss = 518746.89666001\n",
      "Iteration 41, loss = 519647.70780048\n",
      "Iteration 42, loss = 518359.53996944\n",
      "Iteration 43, loss = 519232.82400912\n",
      "Iteration 44, loss = 518765.89565768\n",
      "Iteration 45, loss = 517753.94758986\n",
      "Iteration 46, loss = 518623.13414590\n",
      "Iteration 47, loss = 519667.84626804\n",
      "Iteration 48, loss = 520953.69388508\n",
      "Iteration 49, loss = 518354.68486647\n",
      "Iteration 50, loss = 518295.06178182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 987333.47261030\n",
      "Iteration 2, loss = 567084.76266525\n",
      "Iteration 3, loss = 566883.30718156\n",
      "Iteration 4, loss = 560564.20889591\n",
      "Iteration 5, loss = 560105.31456578\n",
      "Iteration 6, loss = 557790.86296569\n",
      "Iteration 7, loss = 555719.19542684\n",
      "Iteration 8, loss = 556593.23674001\n",
      "Iteration 9, loss = 549448.35592173\n",
      "Iteration 10, loss = 547440.05149936\n",
      "Iteration 11, loss = 543882.81723319\n",
      "Iteration 12, loss = 542881.09511425\n",
      "Iteration 13, loss = 540551.50340039\n",
      "Iteration 14, loss = 538835.69055754\n",
      "Iteration 15, loss = 539490.63043247\n",
      "Iteration 16, loss = 536891.36424285\n",
      "Iteration 17, loss = 534484.45858205\n",
      "Iteration 18, loss = 537686.55835157\n",
      "Iteration 19, loss = 534910.76922741\n",
      "Iteration 20, loss = 535212.33930529\n",
      "Iteration 21, loss = 534504.20046729\n",
      "Iteration 22, loss = 533137.73813398\n",
      "Iteration 23, loss = 535540.99371935\n",
      "Iteration 24, loss = 529997.14963962\n",
      "Iteration 25, loss = 528953.05587768\n",
      "Iteration 26, loss = 530134.96591672\n",
      "Iteration 27, loss = 531525.54840861\n",
      "Iteration 28, loss = 528386.89729181\n",
      "Iteration 29, loss = 530850.96696724\n",
      "Iteration 30, loss = 527019.65239194\n",
      "Iteration 31, loss = 531521.18420980\n",
      "Iteration 32, loss = 528397.62139122\n",
      "Iteration 33, loss = 529529.01634388\n",
      "Iteration 34, loss = 529311.37353991\n",
      "Iteration 35, loss = 525653.19163992\n",
      "Iteration 37, loss = 526416.49844400\n",
      "Iteration 38, loss = 524849.69476094\n",
      "Iteration 39, loss = 524008.98382499\n",
      "Iteration 40, loss = 525440.76704326\n",
      "Iteration 41, loss = 524811.80107459\n",
      "Iteration 42, loss = 526283.75833408\n",
      "Iteration 43, loss = 524378.60316637\n",
      "Iteration 44, loss = 524546.72145754\n",
      "Iteration 45, loss = 525059.51023844\n",
      "Iteration 46, loss = 523150.59129076\n",
      "Iteration 47, loss = 525078.96774259\n",
      "Iteration 48, loss = 522574.78850963\n",
      "Iteration 49, loss = 525778.63646870\n",
      "Iteration 50, loss = 524136.22702420\n",
      "\n",
      "#### MLPRegressor ####\n",
      "score :0.8685\n",
      "[0.86824792 0.86131676 0.85722314 0.86494633 0.86081502]\n",
      "\n",
      "MSE    : 1015055.71 \n",
      "MAE    : 610.00 \n",
      "RMSE   : 1007.50 \n",
      "R2     : 0.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 14.5min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Test score</th>\n",
       "      <th>CV Train score (mean)</th>\n",
       "      <th>%%SVGean Squared error</th>\n",
       "      <th>Mean Absolute error</th>\n",
       "      <th>Root Mean Squared error</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.855497</td>\n",
       "      <td>0.856142</td>\n",
       "      <td>1.115113e+06</td>\n",
       "      <td>660.709925</td>\n",
       "      <td>1055.989094</td>\n",
       "      <td>0.855497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.868863</td>\n",
       "      <td>0.867173</td>\n",
       "      <td>1.011975e+06</td>\n",
       "      <td>601.923403</td>\n",
       "      <td>1005.969513</td>\n",
       "      <td>0.868863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.859651</td>\n",
       "      <td>0.856132</td>\n",
       "      <td>1.083059e+06</td>\n",
       "      <td>621.758773</td>\n",
       "      <td>1040.701258</td>\n",
       "      <td>0.859651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>0.868463</td>\n",
       "      <td>0.862510</td>\n",
       "      <td>1.015056e+06</td>\n",
       "      <td>609.997225</td>\n",
       "      <td>1007.499731</td>\n",
       "      <td>0.868463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  CV Test score  ...  Root Mean Squared error  R2 Score\n",
       "0       LinearRegression       0.855497  ...              1055.989094  0.855497\n",
       "1  RandomForestRegressor       0.868863  ...              1005.969513  0.868863\n",
       "2    KNeighborsRegressor       0.859651  ...              1040.701258  0.859651\n",
       "3           MLPRegressor       0.868463  ...              1007.499731  0.868463\n",
       "\n",
       "[4 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd# Aprendizado de Comitês\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "df_diamonds = pd.read_csv('datasets/diamonds.csv')\n",
    "df_diamonds = df_diamonds.drop(df_diamonds.columns[[0]], axis=1)\n",
    "\n",
    "df_diamonds[df_diamonds.duplicated()].info()\n",
    "\n",
    "df_number_type = df_diamonds.select_dtypes(exclude='O').columns[1:]\n",
    "\n",
    "\n",
    "\n",
    "def range_for_remove_outliers(attr):\n",
    "    df_attr = df_diamonds[attr]\n",
    "    q3 = df_attr.quantile(q=0.75)\n",
    "    q1 = df_attr.quantile(q=0.25)\n",
    "\n",
    "    IQR  = q3 - q1\n",
    "    min_IQR = q1 - 1.5 * IQR\n",
    "    max_IQR = q3 + 1.5 * IQR\n",
    "    \n",
    "    return (min_IQR,max_IQR)\n",
    "\n",
    "def remove_outlier(df_in, col_name):\n",
    "    range_iqr = range_for_remove_outliers(col_name)\n",
    "    df_out = df_in[~((df_in < range_iqr[0]) |(df_in > range_iqr[1])).any(axis=1)]\n",
    "    return df_out\n",
    "\n",
    "\n",
    "df_diamonds_ro = remove_outlier(df_diamonds.select_dtypes(exclude='O'),df_number_type)\n",
    "\n",
    "y=df_diamonds_ro['price']\n",
    "X=df_diamonds_ro.drop('price', axis=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=0.4, random_state=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# sc=StandardScaler()\n",
    "# X_train_tx=sc.fit_transform(X_train)\n",
    "# X_test_tx=sc.transform(X_test)\n",
    "\n",
    "\n",
    "dataset_1 = (X_train, X_test, y_train, y_test, 'dataset_1')\n",
    "\n",
    "# Blank lists for all the details\n",
    "model_=[]\n",
    "cv_score_test=[]\n",
    "cv_score_train=[]\n",
    "mse_=[]\n",
    "mae_=[]\n",
    "rmse_=[]\n",
    "r2_=[]\n",
    "\n",
    "def run_model(model, dataset, modelname):\n",
    "    model.fit(dataset[0], dataset[2])\n",
    "    accuracies=cross_val_score(estimator=model, X=dataset[0], y=dataset[2], cv=5, verbose=1)\n",
    "    y_pred=model.predict(dataset[1])\n",
    "    print('')\n",
    "    score_1=model.score(dataset[1], dataset[3])\n",
    "    print(f'#### {modelname} ####')\n",
    "    print(\"score :%.4f\" %score_1)\n",
    "    print(accuracies)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(dataset[3], y_pred)\n",
    "    mae=mean_absolute_error(dataset[3], y_pred)\n",
    "    rmse=mean_squared_error(dataset[3], y_pred)**0.5\n",
    "    r2=r2_score(dataset[3], y_pred)\n",
    "   \n",
    "    \n",
    "    print('')\n",
    "    print('MSE    : %0.2f ' % mse)\n",
    "    print('MAE    : %0.2f ' % mae)\n",
    "    print('RMSE   : %0.2f ' % rmse)\n",
    "    print('R2     : %0.2f ' % r2)\n",
    "    \n",
    "    ## appending to the lists\n",
    "    \n",
    "    model_.append(modelname)\n",
    "    cv_score_test.append(score_1)\n",
    "    cv_score_train.append(np.mean(accuracies))\n",
    "    mse_.append(mse)\n",
    "    mae_.append(mae)\n",
    "    rmse_.append(rmse)\n",
    "    r2_.append(r2)\n",
    "\n",
    "model_dict={'LinearRegression': LinearRegression(),\n",
    "            'RandomForestRegressor': RandomForestRegressor(), \n",
    "            'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "            'MLPRegressor': MLPRegressor(hidden_layer_sizes=(100,), batch_size=2, learning_rate_init=0.01, learning_rate=\"adaptive\", max_iter=50, verbose=True)\n",
    "           }\n",
    "\n",
    "for models in model_dict:\n",
    "    run_model(model_dict[models], dataset_1, models)\n",
    "\n",
    "accuracy_data=pd.DataFrame(zip(model_, cv_score_test, cv_score_train, mse_, mae_, rmse_, r2_), columns=['Model', 'CV Test score', 'CV Train score (mean)', '%%SVGean Squared error', 'Mean Absolute error', 'Root Mean Squared error', 'R2 Score'])\n",
    "accuracy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSI8XPtG0os6"
   },
   "source": [
    "# Com outliers sem normalizacao com index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yKwCoa3M0vjs",
    "outputId": "0270fe9b-66f7-45c4-98ba-c2c036154dfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 0 entries\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  0 non-null      int64  \n",
      " 1   carat       0 non-null      float64\n",
      " 2   cut         0 non-null      object \n",
      " 3   color       0 non-null      object \n",
      " 4   clarity     0 non-null      object \n",
      " 5   depth       0 non-null      float64\n",
      " 6   table       0 non-null      float64\n",
      " 7   price       0 non-null      int64  \n",
      " 8   x           0 non-null      float64\n",
      " 9   y           0 non-null      float64\n",
      " 10  z           0 non-null      float64\n",
      "dtypes: float64(6), int64(2), object(3)\n",
      "memory usage: 0.0+ bytes\n",
      "\n",
      "#### LinearRegression ####\n",
      "score :0.8555\n",
      "[0.85263266 0.86034477 0.85443187 0.85589875 0.85740044]\n",
      "\n",
      "MSE    : 1115112.97 \n",
      "MAE    : 660.71 \n",
      "RMSE   : 1055.99 \n",
      "R2     : 0.86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   46.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### RandomForestRegressor ####\n",
      "score :0.8693\n",
      "[0.86444634 0.86884417 0.869209   0.86747525 0.86729598]\n",
      "\n",
      "MSE    : 1008884.88 \n",
      "MAE    : 600.43 \n",
      "RMSE   : 1004.43 \n",
      "R2     : 0.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### KNeighborsRegressor ####\n",
      "score :0.8613\n",
      "[0.85350391 0.85496279 0.85767089 0.86240715 0.86095406]\n",
      "\n",
      "MSE    : 1070633.15 \n",
      "MAE    : 617.38 \n",
      "RMSE   : 1034.71 \n",
      "R2     : 0.86 \n",
      "Iteration 1, loss = 670123.57278805\n",
      "Iteration 2, loss = 521968.47456195\n",
      "Iteration 3, loss = 519286.75284513\n",
      "Iteration 4, loss = 516950.13536633\n",
      "Iteration 5, loss = 513324.85334913\n",
      "Iteration 6, loss = 510576.53928142\n",
      "Iteration 7, loss = 509678.10726395\n",
      "Iteration 8, loss = 506284.43236135\n",
      "Iteration 9, loss = 507010.10196432\n",
      "Iteration 10, loss = 504286.16667736\n",
      "Iteration 11, loss = 505188.83909339\n",
      "Iteration 12, loss = 503830.09993460\n",
      "Iteration 13, loss = 503377.88095890\n",
      "Iteration 14, loss = 502138.37509172\n",
      "Iteration 15, loss = 503356.15816265\n",
      "Iteration 16, loss = 501197.24326674\n",
      "Iteration 17, loss = 500113.19596566\n",
      "Iteration 18, loss = 498699.97782468\n",
      "Iteration 19, loss = 497207.78704763\n",
      "Iteration 20, loss = 498913.76101323\n",
      "Iteration 21, loss = 497157.17736510\n",
      "Iteration 22, loss = 498281.15723463\n",
      "Iteration 23, loss = 496745.30469969\n",
      "Iteration 24, loss = 496429.05200538\n",
      "Iteration 25, loss = 496181.91110590\n",
      "Iteration 26, loss = 495231.72853798\n",
      "Iteration 27, loss = 495923.05947338\n",
      "Iteration 28, loss = 494559.63618439\n",
      "Iteration 29, loss = 494674.38768983\n",
      "Iteration 30, loss = 494286.95891518\n",
      "Iteration 31, loss = 494618.89129084\n",
      "Iteration 32, loss = 493727.52076740\n",
      "Iteration 33, loss = 492990.40479060\n",
      "Iteration 34, loss = 492572.22977557\n",
      "Iteration 35, loss = 493860.35818200\n",
      "Iteration 36, loss = 492860.81893915\n",
      "Iteration 37, loss = 492413.10351377\n",
      "Iteration 38, loss = 492425.84480550\n",
      "Iteration 39, loss = 492639.83018763\n",
      "Iteration 40, loss = 493057.69879215\n",
      "Iteration 41, loss = 492515.52395287\n",
      "Iteration 42, loss = 491477.65909976\n",
      "Iteration 43, loss = 492412.47309944\n",
      "Iteration 44, loss = 490321.93030147\n",
      "Iteration 45, loss = 491432.72676997\n",
      "Iteration 46, loss = 492021.26298687\n",
      "Iteration 47, loss = 491274.71480171\n",
      "Iteration 48, loss = 490179.54576960\n",
      "Iteration 49, loss = 489575.98093575\n",
      "Iteration 50, loss = 490901.29312563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 724473.15549483\n",
      "Iteration 2, loss = 516867.69095560\n",
      "Iteration 3, loss = 514346.59580421\n",
      "Iteration 4, loss = 512135.36642159\n",
      "Iteration 5, loss = 510312.87386635\n",
      "Iteration 6, loss = 510151.50163853\n",
      "Iteration 7, loss = 509389.49524690\n",
      "Iteration 8, loss = 505950.94254909\n",
      "Iteration 9, loss = 505507.76634452\n",
      "Iteration 10, loss = 503565.99447618\n",
      "Iteration 11, loss = 503215.28660926\n",
      "Iteration 12, loss = 501239.00400759\n",
      "Iteration 13, loss = 501443.42251041\n",
      "Iteration 14, loss = 500053.37381869\n",
      "Iteration 15, loss = 499350.55558056\n",
      "Iteration 16, loss = 497971.13047819\n",
      "Iteration 17, loss = 498603.65819228\n",
      "Iteration 18, loss = 497508.99164835\n",
      "Iteration 19, loss = 497487.34559824\n",
      "Iteration 20, loss = 497146.66101066\n",
      "Iteration 21, loss = 496166.26960134\n",
      "Iteration 22, loss = 494654.02054020\n",
      "Iteration 23, loss = 495251.65704670\n",
      "Iteration 24, loss = 495785.18315498\n",
      "Iteration 25, loss = 495159.23893078\n",
      "Iteration 26, loss = 493036.82323336\n",
      "Iteration 27, loss = 493709.74425739\n",
      "Iteration 28, loss = 493412.81542190\n",
      "Iteration 29, loss = 491555.18450677\n",
      "Iteration 30, loss = 494422.71514221\n",
      "Iteration 31, loss = 493046.90131106\n",
      "Iteration 32, loss = 491990.13614862\n",
      "Iteration 33, loss = 492803.39087341\n",
      "Iteration 34, loss = 492246.35828697\n",
      "Iteration 35, loss = 492603.18215301\n",
      "Iteration 36, loss = 492443.53818702\n",
      "Iteration 37, loss = 492411.33686479\n",
      "Iteration 38, loss = 490501.32489554\n",
      "Iteration 39, loss = 492651.54471756\n",
      "Iteration 40, loss = 491671.44593121\n",
      "Iteration 41, loss = 491820.79123116\n",
      "Iteration 42, loss = 490667.75986912\n",
      "Iteration 43, loss = 492250.05766601\n",
      "Iteration 44, loss = 491822.17698680\n",
      "Iteration 45, loss = 491922.59571489\n",
      "Iteration 46, loss = 490666.94530636\n",
      "Iteration 47, loss = 491749.14896288\n",
      "Iteration 48, loss = 490165.59679209\n",
      "Iteration 49, loss = 492247.86603289\n",
      "Iteration 50, loss = 490395.04815246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 702650.56975747\n",
      "Iteration 2, loss = 517631.41981552\n",
      "Iteration 3, loss = 513158.53055361\n",
      "Iteration 4, loss = 510859.81462263\n",
      "Iteration 5, loss = 509973.85759519\n",
      "Iteration 6, loss = 508418.93897741\n",
      "Iteration 7, loss = 507639.29236063\n",
      "Iteration 8, loss = 506681.64804751\n",
      "Iteration 9, loss = 506452.35891525\n",
      "Iteration 10, loss = 504197.37659635\n",
      "Iteration 11, loss = 503962.53368987\n",
      "Iteration 12, loss = 503315.98612989\n",
      "Iteration 13, loss = 500810.59641040\n",
      "Iteration 14, loss = 501667.42829479\n",
      "Iteration 15, loss = 501156.44267293\n",
      "Iteration 16, loss = 501289.06149527\n",
      "Iteration 17, loss = 500717.03617488\n",
      "Iteration 18, loss = 498414.36794762\n",
      "Iteration 19, loss = 497156.53140250\n",
      "Iteration 20, loss = 498489.22405380\n",
      "Iteration 21, loss = 497483.19660785\n",
      "Iteration 22, loss = 497167.15006550\n",
      "Iteration 23, loss = 495929.46898808\n",
      "Iteration 24, loss = 495859.56335627\n",
      "Iteration 25, loss = 493611.08705118\n",
      "Iteration 26, loss = 494215.52164902\n",
      "Iteration 27, loss = 492570.76456826\n",
      "Iteration 28, loss = 492264.24358932\n",
      "Iteration 29, loss = 492051.23641506\n",
      "Iteration 30, loss = 490546.70403256\n",
      "Iteration 31, loss = 491529.82444866\n",
      "Iteration 32, loss = 489773.47602832\n",
      "Iteration 33, loss = 490838.98152355\n",
      "Iteration 34, loss = 490370.06508681\n",
      "Iteration 35, loss = 489940.59321575\n",
      "Iteration 36, loss = 488872.33617768\n",
      "Iteration 37, loss = 488745.92035616\n",
      "Iteration 38, loss = 488559.85045904\n",
      "Iteration 39, loss = 488735.36591950\n",
      "Iteration 40, loss = 488779.11050144\n",
      "Iteration 41, loss = 487756.76769349\n",
      "Iteration 42, loss = 488753.65563186\n",
      "Iteration 43, loss = 487293.10720893\n",
      "Iteration 44, loss = 487205.35897288\n",
      "Iteration 45, loss = 487320.60413338\n",
      "Iteration 46, loss = 487158.27640443\n",
      "Iteration 47, loss = 487088.73667236\n",
      "Iteration 48, loss = 485535.35720883\n",
      "Iteration 49, loss = 486057.75850091\n",
      "Iteration 50, loss = 485776.38767931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 708535.22398022\n",
      "Iteration 2, loss = 516161.87814125\n",
      "Iteration 3, loss = 513486.30447058\n",
      "Iteration 4, loss = 511062.83902876\n",
      "Iteration 5, loss = 509027.50753108\n",
      "Iteration 6, loss = 506520.01255614\n",
      "Iteration 7, loss = 505108.90907864\n",
      "Iteration 8, loss = 504067.77291884\n",
      "Iteration 9, loss = 504748.87940178\n",
      "Iteration 10, loss = 503007.14795233\n",
      "Iteration 11, loss = 503421.74231409\n",
      "Iteration 12, loss = 501597.87593082\n",
      "Iteration 13, loss = 500072.40240974\n",
      "Iteration 14, loss = 501200.94383126\n",
      "Iteration 15, loss = 501546.09267131\n",
      "Iteration 16, loss = 499451.93867082\n",
      "Iteration 17, loss = 499178.59723109\n",
      "Iteration 18, loss = 499004.11883552\n",
      "Iteration 19, loss = 498397.72832046\n",
      "Iteration 20, loss = 497155.73169534\n",
      "Iteration 21, loss = 499061.58630036\n",
      "Iteration 22, loss = 497922.27913238\n",
      "Iteration 23, loss = 498103.40558834\n",
      "Iteration 24, loss = 498096.52345837\n",
      "Iteration 25, loss = 496802.02860724\n",
      "Iteration 26, loss = 496250.31567727\n",
      "Iteration 27, loss = 496844.91579804\n",
      "Iteration 28, loss = 495407.78533664\n",
      "Iteration 29, loss = 493805.26497639\n",
      "Iteration 30, loss = 495964.86449727\n",
      "Iteration 31, loss = 495139.72563780\n",
      "Iteration 32, loss = 494574.56494342\n",
      "Iteration 33, loss = 492825.50569792\n",
      "Iteration 34, loss = 493438.36683910\n",
      "Iteration 35, loss = 490893.30871051\n",
      "Iteration 36, loss = 490893.98208146\n",
      "Iteration 37, loss = 489955.61776027\n",
      "Iteration 38, loss = 489515.06806397\n",
      "Iteration 39, loss = 490710.99077897\n",
      "Iteration 40, loss = 490465.30487872\n",
      "Iteration 41, loss = 489704.10776030\n",
      "Iteration 42, loss = 488856.59301753\n",
      "Iteration 43, loss = 489089.75566006\n",
      "Iteration 44, loss = 487813.23936536\n",
      "Iteration 45, loss = 488301.37081232\n",
      "Iteration 46, loss = 488424.62677400\n",
      "Iteration 47, loss = 487969.42379380\n",
      "Iteration 48, loss = 487649.96504603\n",
      "Iteration 49, loss = 488395.05740007\n",
      "Iteration 50, loss = 486021.91915810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 715519.42027171\n",
      "Iteration 2, loss = 519263.60713830\n",
      "Iteration 3, loss = 516685.65101149\n",
      "Iteration 4, loss = 513066.71537568\n",
      "Iteration 5, loss = 511769.98321736\n",
      "Iteration 6, loss = 508914.93414239\n",
      "Iteration 7, loss = 508894.02137533\n",
      "Iteration 8, loss = 508098.24627085\n",
      "Iteration 9, loss = 507105.00302842\n",
      "Iteration 10, loss = 505479.79595781\n",
      "Iteration 11, loss = 505845.75026194\n",
      "Iteration 12, loss = 504480.57850116\n",
      "Iteration 13, loss = 504608.54997202\n",
      "Iteration 14, loss = 502301.53836215\n",
      "Iteration 15, loss = 502245.52193936\n",
      "Iteration 16, loss = 502268.50428972\n",
      "Iteration 17, loss = 502066.22103071\n",
      "Iteration 18, loss = 501023.19432969\n",
      "Iteration 19, loss = 500055.49524862\n",
      "Iteration 20, loss = 500281.40233748\n",
      "Iteration 21, loss = 500015.78295753\n",
      "Iteration 22, loss = 498968.79375720\n",
      "Iteration 23, loss = 498442.90224462\n",
      "Iteration 24, loss = 498726.10405273\n",
      "Iteration 25, loss = 497905.08513492\n",
      "Iteration 26, loss = 498212.43528216\n",
      "Iteration 27, loss = 500089.64376635\n",
      "Iteration 28, loss = 498040.27250930\n",
      "Iteration 29, loss = 498588.14447046\n",
      "Iteration 30, loss = 497835.89000037\n",
      "Iteration 31, loss = 497262.05859878\n",
      "Iteration 32, loss = 497282.89608248\n",
      "Iteration 33, loss = 497467.74695561\n",
      "Iteration 34, loss = 496262.98533488\n",
      "Iteration 35, loss = 496194.63183792\n",
      "Iteration 36, loss = 495992.27665741\n",
      "Iteration 37, loss = 494307.57765856\n",
      "Iteration 38, loss = 494268.84909576\n",
      "Iteration 39, loss = 493739.59130697\n",
      "Iteration 40, loss = 493679.15074234\n",
      "Iteration 41, loss = 493044.31523279\n",
      "Iteration 42, loss = 492535.48187030\n",
      "Iteration 43, loss = 492714.58874877\n",
      "Iteration 44, loss = 491217.81613643\n",
      "Iteration 45, loss = 492719.75298360\n",
      "Iteration 46, loss = 491459.04627101\n",
      "Iteration 47, loss = 493137.65970216\n",
      "Iteration 48, loss = 491737.21225874\n",
      "Iteration 49, loss = 491976.23219057\n",
      "Iteration 50, loss = 489792.04999559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 718726.91545018\n",
      "Iteration 2, loss = 523874.92735195\n",
      "Iteration 3, loss = 522739.12487347\n",
      "Iteration 4, loss = 517914.31765188\n",
      "Iteration 5, loss = 516960.58971386\n",
      "Iteration 6, loss = 515935.26773350\n",
      "Iteration 7, loss = 513239.21275214\n",
      "Iteration 8, loss = 512570.18646103\n",
      "Iteration 9, loss = 509971.67212859\n",
      "Iteration 10, loss = 509170.44253139\n",
      "Iteration 11, loss = 510035.27905517\n",
      "Iteration 12, loss = 508972.34228566\n",
      "Iteration 13, loss = 507514.53712739\n",
      "Iteration 14, loss = 506315.74172438\n",
      "Iteration 15, loss = 506491.03555646\n",
      "Iteration 16, loss = 506206.02740251\n",
      "Iteration 17, loss = 505896.22905015\n",
      "Iteration 18, loss = 506442.53055592\n",
      "Iteration 19, loss = 504602.98583631\n",
      "Iteration 20, loss = 503169.00706609\n",
      "Iteration 21, loss = 503350.52335823\n",
      "Iteration 22, loss = 502926.60081210\n",
      "Iteration 23, loss = 502854.42011508\n",
      "Iteration 24, loss = 502033.82622071\n",
      "Iteration 25, loss = 502245.78230022\n",
      "Iteration 26, loss = 499484.02522695\n",
      "Iteration 27, loss = 501121.88281409\n",
      "Iteration 28, loss = 499602.68270104\n",
      "Iteration 29, loss = 497327.77715266\n",
      "Iteration 30, loss = 499676.93283055\n",
      "Iteration 31, loss = 498901.95586233\n",
      "Iteration 32, loss = 498832.67166906\n",
      "Iteration 33, loss = 496626.85919125\n",
      "Iteration 34, loss = 499040.89330036\n",
      "Iteration 35, loss = 498015.35399573\n",
      "Iteration 36, loss = 496721.09648518\n",
      "Iteration 37, loss = 496763.79640838\n",
      "Iteration 38, loss = 496097.78437994\n",
      "Iteration 39, loss = 496144.45574292\n",
      "Iteration 40, loss = 495993.34983982\n",
      "Iteration 41, loss = 495403.98332727\n",
      "Iteration 42, loss = 494901.37995216\n",
      "Iteration 43, loss = 495022.79808443\n",
      "Iteration 44, loss = 494320.47850146\n",
      "Iteration 45, loss = 494629.54284379\n",
      "Iteration 46, loss = 494040.39755396\n",
      "Iteration 47, loss = 493842.98222553\n",
      "Iteration 48, loss = 493783.97710626\n",
      "Iteration 49, loss = 494440.72596168\n",
      "Iteration 50, loss = 494523.96241154\n",
      "\n",
      "#### MLPRegressor ####\n",
      "score :0.8711\n",
      "[0.87332983 0.87293731 0.86871851 0.86833719 0.87452236]\n",
      "\n",
      "MSE    : 994942.71 \n",
      "MAE    : 597.98 \n",
      "RMSE   : 997.47 \n",
      "R2     : 0.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 14.0min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Test score</th>\n",
       "      <th>CV Train score (mean)</th>\n",
       "      <th>%%SVGean Squared error</th>\n",
       "      <th>Mean Absolute error</th>\n",
       "      <th>Root Mean Squared error</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.855497</td>\n",
       "      <td>0.856142</td>\n",
       "      <td>1.115113e+06</td>\n",
       "      <td>660.709925</td>\n",
       "      <td>1055.989094</td>\n",
       "      <td>0.855497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.869263</td>\n",
       "      <td>0.867454</td>\n",
       "      <td>1.008885e+06</td>\n",
       "      <td>600.425577</td>\n",
       "      <td>1004.432616</td>\n",
       "      <td>0.869263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.861261</td>\n",
       "      <td>0.857900</td>\n",
       "      <td>1.070633e+06</td>\n",
       "      <td>617.382507</td>\n",
       "      <td>1034.714041</td>\n",
       "      <td>0.861261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>0.871070</td>\n",
       "      <td>0.871569</td>\n",
       "      <td>9.949427e+05</td>\n",
       "      <td>597.978741</td>\n",
       "      <td>997.468148</td>\n",
       "      <td>0.871070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  CV Test score  ...  Root Mean Squared error  R2 Score\n",
       "0       LinearRegression       0.855497  ...              1055.989094  0.855497\n",
       "1  RandomForestRegressor       0.869263  ...              1004.432616  0.869263\n",
       "2    KNeighborsRegressor       0.861261  ...              1034.714041  0.861261\n",
       "3           MLPRegressor       0.871070  ...               997.468148  0.871070\n",
       "\n",
       "[4 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd# Aprendizado de Comitês\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "df_diamonds = pd.read_csv('datasets/diamonds.csv')\n",
    "df_diamonds[df_diamonds.duplicated()].info()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=0.4, random_state=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "dataset_1 = (X_train, X_test, y_train, y_test, 'dataset_1')\n",
    "\n",
    "# Blank lists for all the details\n",
    "model_=[]\n",
    "cv_score_test=[]\n",
    "cv_score_train=[]\n",
    "mse_=[]\n",
    "mae_=[]\n",
    "rmse_=[]\n",
    "r2_=[]\n",
    "\n",
    "def run_model(model, dataset, modelname):\n",
    "    model.fit(dataset[0], dataset[2])\n",
    "    accuracies=cross_val_score(estimator=model, X=dataset[0], y=dataset[2], cv=5, verbose=1)\n",
    "    y_pred=model.predict(dataset[1])\n",
    "    print('')\n",
    "    score_1=model.score(dataset[1], dataset[3])\n",
    "    print(f'#### {modelname} ####')\n",
    "    print(\"score :%.4f\" %score_1)\n",
    "    print(accuracies)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(dataset[3], y_pred)\n",
    "    mae=mean_absolute_error(dataset[3], y_pred)\n",
    "    rmse=mean_squared_error(dataset[3], y_pred)**0.5\n",
    "    r2=r2_score(dataset[3], y_pred)\n",
    "   \n",
    "    \n",
    "    print('')\n",
    "    print('MSE    : %0.2f ' % mse)\n",
    "    print('MAE    : %0.2f ' % mae)\n",
    "    print('RMSE   : %0.2f ' % rmse)\n",
    "    print('R2     : %0.2f ' % r2)\n",
    "    \n",
    "    ## appending to the lists\n",
    "    \n",
    "    model_.append(modelname)\n",
    "    cv_score_test.append(score_1)\n",
    "    cv_score_train.append(np.mean(accuracies))\n",
    "    mse_.append(mse)\n",
    "    mae_.append(mae)\n",
    "    rmse_.append(rmse)\n",
    "    r2_.append(r2)\n",
    "\n",
    "model_dict={'LinearRegression': LinearRegression(), \n",
    "           'RandomForestRegressor': RandomForestRegressor(), \n",
    "            'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "            'MLPRegressor': MLPRegressor(hidden_layer_sizes=(100,), batch_size=2, learning_rate_init=0.01, learning_rate=\"adaptive\", max_iter=50, verbose=True)\n",
    "\n",
    "\n",
    "           }\n",
    "\n",
    "for models in model_dict:\n",
    "    run_model(model_dict[models], dataset_1, models)\n",
    "\n",
    "accuracy_data=pd.DataFrame(zip(model_, cv_score_test, cv_score_train, mse_, mae_, rmse_, r2_), columns=['Model', 'CV Test score', 'CV Train score (mean)', '%%SVGean Squared error', 'Mean Absolute error', 'Root Mean Squared error', 'R2 Score'])\n",
    "accuracy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ok9PJsgV1qaH"
   },
   "source": [
    "\n",
    "# Sem Outliers com normalizacao sem index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "J-GJ0H8y1w-p",
    "outputId": "c9a5cf1c-9c94-46f7-cdbd-8b7d3c8fb01a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 0 entries\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  0 non-null      int64  \n",
      " 1   carat       0 non-null      float64\n",
      " 2   cut         0 non-null      object \n",
      " 3   color       0 non-null      object \n",
      " 4   clarity     0 non-null      object \n",
      " 5   depth       0 non-null      float64\n",
      " 6   table       0 non-null      float64\n",
      " 7   price       0 non-null      int64  \n",
      " 8   x           0 non-null      float64\n",
      " 9   y           0 non-null      float64\n",
      " 10  z           0 non-null      float64\n",
      "dtypes: float64(6), int64(2), object(3)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### LinearRegression ####\n",
      "score :0.8555\n",
      "[0.85263266 0.86034477 0.85443187 0.85589875 0.85740044]\n",
      "\n",
      "MSE    : 1115112.97 \n",
      "MAE    : 660.71 \n",
      "RMSE   : 1055.99 \n",
      "R2     : 0.86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   46.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### RandomForestRegressor ####\n",
      "score :0.8686\n",
      "[0.86544667 0.86808335 0.86831515 0.86731006 0.86702119]\n",
      "\n",
      "MSE    : 1013805.92 \n",
      "MAE    : 602.81 \n",
      "RMSE   : 1006.88 \n",
      "R2     : 0.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### KNeighborsRegressor ####\n",
      "score :0.8613\n",
      "[0.85350391 0.85496279 0.85767089 0.86240715 0.86095406]\n",
      "\n",
      "MSE    : 1070633.15 \n",
      "MAE    : 617.38 \n",
      "RMSE   : 1034.71 \n",
      "R2     : 0.86 \n",
      "Iteration 1, loss = 666585.33623783\n",
      "Iteration 2, loss = 519373.55499862\n",
      "Iteration 3, loss = 517383.82777375\n",
      "Iteration 4, loss = 513308.66748300\n",
      "Iteration 5, loss = 511496.59034624\n",
      "Iteration 6, loss = 509941.67107923\n",
      "Iteration 7, loss = 507121.47645375\n",
      "Iteration 8, loss = 507248.43528854\n",
      "Iteration 9, loss = 505895.12569100\n",
      "Iteration 10, loss = 505215.57834367\n",
      "Iteration 11, loss = 504649.39381326\n",
      "Iteration 12, loss = 503713.90034564\n",
      "Iteration 13, loss = 502427.45958943\n",
      "Iteration 14, loss = 501123.09606855\n",
      "Iteration 15, loss = 499188.69450853\n",
      "Iteration 16, loss = 498622.82659672\n",
      "Iteration 17, loss = 498521.00101287\n",
      "Iteration 18, loss = 497734.15921653\n",
      "Iteration 19, loss = 497343.90949426\n",
      "Iteration 20, loss = 495050.79781315\n",
      "Iteration 21, loss = 494113.35259859\n",
      "Iteration 22, loss = 494880.63544982\n",
      "Iteration 23, loss = 494146.53654755\n",
      "Iteration 24, loss = 492826.90347520\n",
      "Iteration 25, loss = 492045.82004884\n",
      "Iteration 26, loss = 491510.17603229\n",
      "Iteration 27, loss = 492793.40363742\n",
      "Iteration 28, loss = 493165.30641402\n",
      "Iteration 29, loss = 492009.81926782\n",
      "Iteration 30, loss = 491160.05534540\n",
      "Iteration 31, loss = 490711.11726217\n",
      "Iteration 32, loss = 491178.46511418\n",
      "Iteration 33, loss = 491065.75439102\n",
      "Iteration 34, loss = 490481.09246627\n",
      "Iteration 35, loss = 489182.41336748\n",
      "Iteration 36, loss = 489564.14234957\n",
      "Iteration 37, loss = 489555.79998220\n",
      "Iteration 38, loss = 489031.40383383\n",
      "Iteration 39, loss = 489769.18631795\n",
      "Iteration 40, loss = 488877.71963928\n",
      "Iteration 41, loss = 489677.84021844\n",
      "Iteration 42, loss = 490038.71731346\n",
      "Iteration 43, loss = 489030.37715348\n",
      "Iteration 44, loss = 488523.76100033\n",
      "Iteration 45, loss = 487880.66836267\n",
      "Iteration 46, loss = 486516.72452607\n",
      "Iteration 47, loss = 487335.01912736\n",
      "Iteration 48, loss = 488612.75093110\n",
      "Iteration 49, loss = 487574.45959853\n",
      "Iteration 50, loss = 486990.28727965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 717868.28738532\n",
      "Iteration 2, loss = 517044.21686080\n",
      "Iteration 3, loss = 514475.54121946\n",
      "Iteration 4, loss = 511309.29313772\n",
      "Iteration 5, loss = 511323.37535723\n",
      "Iteration 6, loss = 509198.11949090\n",
      "Iteration 7, loss = 508691.21759355\n",
      "Iteration 8, loss = 507504.71824568\n",
      "Iteration 9, loss = 507749.48757419\n",
      "Iteration 10, loss = 506179.76303132\n",
      "Iteration 11, loss = 506045.87639353\n",
      "Iteration 12, loss = 505068.28480854\n",
      "Iteration 13, loss = 504653.07946942\n",
      "Iteration 14, loss = 504002.87358900\n",
      "Iteration 15, loss = 504151.45169696\n",
      "Iteration 16, loss = 502719.06194855\n",
      "Iteration 17, loss = 502440.25244034\n",
      "Iteration 18, loss = 502669.81793176\n",
      "Iteration 19, loss = 503017.24083248\n",
      "Iteration 20, loss = 501124.80587032\n",
      "Iteration 21, loss = 499935.71979047\n",
      "Iteration 22, loss = 500778.97996266\n",
      "Iteration 23, loss = 498079.38262680\n",
      "Iteration 24, loss = 498296.16368857\n",
      "Iteration 25, loss = 496446.62568560\n",
      "Iteration 26, loss = 496040.99137761\n",
      "Iteration 27, loss = 496119.55363629\n",
      "Iteration 28, loss = 496220.00034697\n",
      "Iteration 29, loss = 493175.71640768\n",
      "Iteration 30, loss = 494745.12918251\n",
      "Iteration 31, loss = 493932.66661920\n",
      "Iteration 32, loss = 493658.85977153\n",
      "Iteration 33, loss = 491986.22150116\n",
      "Iteration 34, loss = 493594.66784436\n",
      "Iteration 35, loss = 494099.67284185\n",
      "Iteration 36, loss = 492422.77335558\n",
      "Iteration 37, loss = 493679.46803167\n",
      "Iteration 38, loss = 492531.44388900\n",
      "Iteration 39, loss = 492660.60076383\n",
      "Iteration 40, loss = 492526.46357131\n",
      "Iteration 41, loss = 492161.96002680\n",
      "Iteration 42, loss = 490583.27058395\n",
      "Iteration 43, loss = 491844.56170823\n",
      "Iteration 44, loss = 492098.63755453\n",
      "Iteration 45, loss = 490824.64843520\n",
      "Iteration 46, loss = 490939.34428603\n",
      "Iteration 47, loss = 489233.34451243\n",
      "Iteration 48, loss = 491031.59205662\n",
      "Iteration 49, loss = 491536.85929801\n",
      "Iteration 50, loss = 490741.17051584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 708825.94489371\n",
      "Iteration 2, loss = 519976.07562395\n",
      "Iteration 3, loss = 518483.91864690\n",
      "Iteration 4, loss = 513105.74891213\n",
      "Iteration 5, loss = 513445.12499222\n",
      "Iteration 6, loss = 511125.25593115\n",
      "Iteration 7, loss = 508471.74000788\n",
      "Iteration 8, loss = 507318.95534016\n",
      "Iteration 9, loss = 504895.10330514\n",
      "Iteration 10, loss = 506429.06839888\n",
      "Iteration 11, loss = 505617.32110057\n",
      "Iteration 12, loss = 504343.86445714\n",
      "Iteration 13, loss = 502830.92654269\n",
      "Iteration 14, loss = 501676.69082943\n",
      "Iteration 15, loss = 502197.30943127\n",
      "Iteration 16, loss = 499659.12848724\n",
      "Iteration 17, loss = 501836.72966079\n",
      "Iteration 18, loss = 499820.51009240\n",
      "Iteration 19, loss = 500315.25154888\n",
      "Iteration 20, loss = 498666.03924820\n",
      "Iteration 21, loss = 498502.83715768\n",
      "Iteration 22, loss = 498596.13768824\n",
      "Iteration 23, loss = 499290.78498232\n",
      "Iteration 24, loss = 497965.65082718\n",
      "Iteration 25, loss = 498773.65410628\n",
      "Iteration 26, loss = 497285.58604657\n",
      "Iteration 27, loss = 496636.61000341\n",
      "Iteration 28, loss = 496929.25439657\n",
      "Iteration 29, loss = 496956.89512726\n",
      "Iteration 30, loss = 497081.26260316\n",
      "Iteration 31, loss = 496979.97511912\n",
      "Iteration 32, loss = 496684.68371568\n",
      "Iteration 33, loss = 495480.24971456\n",
      "Iteration 34, loss = 495659.78423526\n",
      "Iteration 35, loss = 495426.29706960\n",
      "Iteration 36, loss = 495046.58688066\n",
      "Iteration 37, loss = 493894.39953981\n",
      "Iteration 38, loss = 493362.85294088\n",
      "Iteration 39, loss = 492443.58911891\n",
      "Iteration 41, loss = 491707.43021830\n",
      "Iteration 42, loss = 492366.68632327\n",
      "Iteration 43, loss = 490459.39232989\n",
      "Iteration 44, loss = 493096.42471379\n",
      "Iteration 45, loss = 490707.73153849\n",
      "Iteration 46, loss = 490418.75412159\n",
      "Iteration 47, loss = 491881.82606338\n",
      "Iteration 48, loss = 490577.06406000\n",
      "Iteration 49, loss = 490517.93986741\n",
      "Iteration 50, loss = 490639.55679890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 725535.99598354\n",
      "Iteration 2, loss = 516336.40725559\n",
      "Iteration 3, loss = 511906.77497371\n",
      "Iteration 4, loss = 510169.55820234\n",
      "Iteration 5, loss = 508630.32734013\n",
      "Iteration 6, loss = 506952.99594205\n",
      "Iteration 7, loss = 505327.49123731\n",
      "Iteration 8, loss = 504656.22329911\n",
      "Iteration 9, loss = 504451.27951633\n",
      "Iteration 10, loss = 501715.45984677\n",
      "Iteration 11, loss = 501996.93693130\n",
      "Iteration 12, loss = 500647.93154506\n",
      "Iteration 13, loss = 499912.24076349\n",
      "Iteration 14, loss = 501193.28836083\n",
      "Iteration 15, loss = 500033.59516565\n",
      "Iteration 16, loss = 498717.52040998\n",
      "Iteration 17, loss = 498800.45122394\n",
      "Iteration 18, loss = 497441.74894309\n",
      "Iteration 19, loss = 497555.80550396\n",
      "Iteration 20, loss = 498149.20239259\n",
      "Iteration 21, loss = 497161.58692128\n",
      "Iteration 22, loss = 495912.03383013\n",
      "Iteration 23, loss = 495623.91687271\n",
      "Iteration 24, loss = 495250.56512722\n",
      "Iteration 25, loss = 494898.27037126\n",
      "Iteration 26, loss = 494978.87691393\n",
      "Iteration 27, loss = 495831.07006358\n",
      "Iteration 28, loss = 494085.14698142\n",
      "Iteration 29, loss = 494481.32426846\n",
      "Iteration 30, loss = 494761.52865159\n",
      "Iteration 31, loss = 493983.89666570\n",
      "Iteration 32, loss = 494402.51941657\n",
      "Iteration 33, loss = 492263.75562260\n",
      "Iteration 34, loss = 492017.25020944\n",
      "Iteration 35, loss = 493873.16482099\n",
      "Iteration 36, loss = 493154.57860294\n",
      "Iteration 37, loss = 491309.42753343\n",
      "Iteration 38, loss = 489779.20113785\n",
      "Iteration 39, loss = 491436.69562247\n",
      "Iteration 40, loss = 490815.24724082\n",
      "Iteration 41, loss = 490201.76551988\n",
      "Iteration 42, loss = 490889.85514165\n",
      "Iteration 43, loss = 490422.21649785\n",
      "Iteration 44, loss = 490270.63252710\n",
      "Iteration 45, loss = 490135.87232399\n",
      "Iteration 46, loss = 489143.11001650\n",
      "Iteration 47, loss = 487466.04580108\n",
      "Iteration 48, loss = 489384.37183138\n",
      "Iteration 49, loss = 489193.86307121\n",
      "Iteration 50, loss = 487518.08380023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 706641.30618653\n",
      "Iteration 2, loss = 517655.83267962\n",
      "Iteration 3, loss = 515075.32663597\n",
      "Iteration 4, loss = 511184.43754861\n",
      "Iteration 5, loss = 510307.72840318\n",
      "Iteration 6, loss = 508204.97803664\n",
      "Iteration 7, loss = 507572.64935372\n",
      "Iteration 8, loss = 505268.20584342\n",
      "Iteration 9, loss = 505901.63495409\n",
      "Iteration 10, loss = 503507.90800688\n",
      "Iteration 11, loss = 502593.83704049\n",
      "Iteration 12, loss = 502403.54137216\n",
      "Iteration 13, loss = 502407.13146661\n",
      "Iteration 14, loss = 500982.78387652\n",
      "Iteration 15, loss = 501804.14986804\n",
      "Iteration 16, loss = 500334.01380459\n",
      "Iteration 17, loss = 498219.05943926\n",
      "Iteration 18, loss = 499243.01301747\n",
      "Iteration 19, loss = 498314.40681804\n",
      "Iteration 20, loss = 499060.15936613\n",
      "Iteration 21, loss = 498072.32581519\n",
      "Iteration 22, loss = 499001.55429448\n",
      "Iteration 23, loss = 497782.41668657\n",
      "Iteration 24, loss = 498670.32730362\n",
      "Iteration 25, loss = 496434.51210361\n",
      "Iteration 26, loss = 497064.31318465\n",
      "Iteration 27, loss = 496766.32093746\n",
      "Iteration 28, loss = 497064.44874214\n",
      "Iteration 29, loss = 498273.01090738\n",
      "Iteration 30, loss = 497155.69532326\n",
      "Iteration 31, loss = 494647.32181505\n",
      "Iteration 32, loss = 494705.26372420\n",
      "Iteration 33, loss = 496890.72167623\n",
      "Iteration 34, loss = 493796.85153017\n",
      "Iteration 35, loss = 496076.22046911\n",
      "Iteration 36, loss = 496654.66565531\n",
      "Iteration 37, loss = 495282.94027325\n",
      "Iteration 38, loss = 495970.40038302\n",
      "Iteration 39, loss = 494976.20814855\n",
      "Iteration 40, loss = 493805.01301134\n",
      "Iteration 41, loss = 495264.59908049\n",
      "Iteration 42, loss = 493163.77509244\n",
      "Iteration 43, loss = 493698.57302985\n",
      "Iteration 44, loss = 492742.08419774\n",
      "Iteration 45, loss = 493889.42000152\n",
      "Iteration 46, loss = 492460.38230871\n",
      "Iteration 47, loss = 492183.94628928\n",
      "Iteration 48, loss = 492453.21909203\n",
      "Iteration 49, loss = 491531.62890827\n",
      "Iteration 50, loss = 493100.52471960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 708979.86924119\n",
      "Iteration 2, loss = 523753.87403829\n",
      "Iteration 3, loss = 518004.24854207\n",
      "Iteration 4, loss = 516289.80827216\n",
      "Iteration 5, loss = 514427.25670101\n",
      "Iteration 6, loss = 512767.41769652\n",
      "Iteration 7, loss = 512112.06289844\n",
      "Iteration 8, loss = 511080.18489626\n",
      "Iteration 9, loss = 510947.29863089\n",
      "Iteration 10, loss = 510760.38109316\n",
      "Iteration 11, loss = 507947.87817147\n",
      "Iteration 12, loss = 508870.35918202\n",
      "Iteration 13, loss = 508303.92852710\n",
      "Iteration 14, loss = 506316.11023693\n",
      "Iteration 15, loss = 507036.08415427\n",
      "Iteration 16, loss = 506299.00118955\n",
      "Iteration 17, loss = 505510.76969252\n",
      "Iteration 18, loss = 504891.82188392\n",
      "Iteration 19, loss = 504332.44024344\n",
      "Iteration 20, loss = 502767.27892224\n",
      "Iteration 21, loss = 502121.23240865\n",
      "Iteration 22, loss = 503301.30518165\n",
      "Iteration 23, loss = 502797.28715388\n",
      "Iteration 24, loss = 501540.66579415\n",
      "Iteration 25, loss = 502851.41009083\n",
      "Iteration 26, loss = 501816.55567434\n",
      "Iteration 27, loss = 500707.76852324\n",
      "Iteration 28, loss = 499338.14171485\n",
      "Iteration 29, loss = 501222.20398653\n",
      "Iteration 30, loss = 499157.44315589\n",
      "Iteration 31, loss = 499924.03945773\n",
      "Iteration 32, loss = 498919.54985325\n",
      "Iteration 33, loss = 497930.61110272\n",
      "Iteration 34, loss = 498530.23592388\n",
      "Iteration 35, loss = 498602.34185438\n",
      "Iteration 36, loss = 498125.21231375\n",
      "Iteration 37, loss = 499389.98604050\n",
      "Iteration 38, loss = 498751.31416469\n",
      "Iteration 39, loss = 497097.14972977\n",
      "Iteration 40, loss = 498837.47446160\n",
      "Iteration 41, loss = 497606.49511781\n",
      "Iteration 42, loss = 497334.11890131\n",
      "Iteration 43, loss = 497429.78023785\n",
      "Iteration 44, loss = 496920.20938380\n",
      "Iteration 45, loss = 497516.69328049\n",
      "Iteration 46, loss = 496276.28911611\n",
      "Iteration 47, loss = 495848.28399297\n",
      "Iteration 48, loss = 496281.82810401\n",
      "Iteration 49, loss = 496726.15560478\n",
      "Iteration 50, loss = 496299.48993922\n",
      "\n",
      "#### MLPRegressor ####\n",
      "score :0.8721\n",
      "[0.87353541 0.87484047 0.87055027 0.87344244 0.86963274]\n",
      "\n",
      "MSE    : 987069.25 \n",
      "MAE    : 601.39 \n",
      "RMSE   : 993.51 \n",
      "R2     : 0.87 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 14.2min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Test score</th>\n",
       "      <th>CV Train score (mean)</th>\n",
       "      <th>%%SVGean Squared error</th>\n",
       "      <th>Mean Absolute error</th>\n",
       "      <th>Root Mean Squared error</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.855497</td>\n",
       "      <td>0.856142</td>\n",
       "      <td>1.115113e+06</td>\n",
       "      <td>660.709925</td>\n",
       "      <td>1055.989094</td>\n",
       "      <td>0.855497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.868625</td>\n",
       "      <td>0.867235</td>\n",
       "      <td>1.013806e+06</td>\n",
       "      <td>602.805088</td>\n",
       "      <td>1006.879296</td>\n",
       "      <td>0.868625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.861261</td>\n",
       "      <td>0.857900</td>\n",
       "      <td>1.070633e+06</td>\n",
       "      <td>617.382507</td>\n",
       "      <td>1034.714041</td>\n",
       "      <td>0.861261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>0.872090</td>\n",
       "      <td>0.872400</td>\n",
       "      <td>9.870693e+05</td>\n",
       "      <td>601.392302</td>\n",
       "      <td>993.513589</td>\n",
       "      <td>0.872090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  CV Test score  ...  Root Mean Squared error  R2 Score\n",
       "0       LinearRegression       0.855497  ...              1055.989094  0.855497\n",
       "1  RandomForestRegressor       0.868625  ...              1006.879296  0.868625\n",
       "2    KNeighborsRegressor       0.861261  ...              1034.714041  0.861261\n",
       "3           MLPRegressor       0.872090  ...               993.513589  0.872090\n",
       "\n",
       "[4 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd# Aprendizado de Comitês\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "df_diamonds = pd.read_csv('datasets/diamonds.csv')\n",
    "df_diamonds[df_diamonds.duplicated()].info()\n",
    "\n",
    "df_number_type = df_diamonds.select_dtypes(exclude='O').columns[1:]\n",
    "df_diamonds = df_diamonds.drop(df_diamonds.columns[[0]], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def range_for_remove_outliers(attr):\n",
    "    df_attr = df_diamonds[attr]\n",
    "    q3 = df_attr.quantile(q=0.75)\n",
    "    q1 = df_attr.quantile(q=0.25)\n",
    "\n",
    "    IQR  = q3 - q1\n",
    "    min_IQR = q1 - 1.5 * IQR\n",
    "    max_IQR = q3 + 1.5 * IQR\n",
    "    \n",
    "    return (min_IQR,max_IQR)\n",
    "\n",
    "def remove_outlier(df_in, col_name):\n",
    "    range_iqr = range_for_remove_outliers(col_name)\n",
    "    df_out = df_in[~((df_in < range_iqr[0]) |(df_in > range_iqr[1])).any(axis=1)]\n",
    "    return df_out\n",
    "\n",
    "\n",
    "df_diamonds = remove_outlier(df_diamonds, df_number_type) \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=0.4, random_state=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "dataset_1 = (X_train, X_test, y_train, y_test, 'dataset_1')\n",
    "\n",
    "# Blank lists for all the details\n",
    "model_=[]\n",
    "cv_score_test=[]\n",
    "cv_score_train=[]\n",
    "mse_=[]\n",
    "mae_=[]\n",
    "rmse_=[]\n",
    "r2_=[]\n",
    "\n",
    "def run_model(model, dataset, modelname):\n",
    "    model.fit(dataset[0], dataset[2])\n",
    "    accuracies=cross_val_score(estimator=model, X=dataset[0], y=dataset[2], cv=5, verbose=1)\n",
    "    y_pred=model.predict(dataset[1])\n",
    "    print('')\n",
    "    score_1=model.score(dataset[1], dataset[3])\n",
    "    print(f'#### {modelname} ####')\n",
    "    print(\"score :%.4f\" %score_1)\n",
    "    print(accuracies)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(dataset[3], y_pred)\n",
    "    mae=mean_absolute_error(dataset[3], y_pred)\n",
    "    rmse=mean_squared_error(dataset[3], y_pred)**0.5\n",
    "    r2=r2_score(dataset[3], y_pred)\n",
    "   \n",
    "    \n",
    "    print('')\n",
    "    print('MSE    : %0.2f ' % mse)\n",
    "    print('MAE    : %0.2f ' % mae)\n",
    "    print('RMSE   : %0.2f ' % rmse)\n",
    "    print('R2     : %0.2f ' % r2)\n",
    "    \n",
    "    ## appending to the lists\n",
    "    \n",
    "    model_.append(modelname)\n",
    "    cv_score_test.append(score_1)\n",
    "    cv_score_train.append(np.mean(accuracies))\n",
    "    mse_.append(mse)\n",
    "    mae_.append(mae)\n",
    "    rmse_.append(rmse)\n",
    "    r2_.append(r2)\n",
    "\n",
    "model_dict={'LinearRegression': LinearRegression(), \n",
    "            'RandomForestRegressor': RandomForestRegressor(), \n",
    "            'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "            'MLPRegressor': MLPRegressor(hidden_layer_sizes=(100,), batch_size=2, learning_rate_init=0.01, learning_rate=\"adaptive\", max_iter=50, verbose=True)\n",
    "\n",
    "\n",
    "           }\n",
    "\n",
    "for models in model_dict:\n",
    "    run_model(model_dict[models], dataset_1, models)\n",
    "\n",
    "accuracy_data=pd.DataFrame(zip(model_, cv_score_test, cv_score_train, mse_, mae_, rmse_, r2_), columns=['Model', 'CV Test score', 'CV Train score (mean)', '%%SVGean Squared error', 'Mean Absolute error', 'Root Mean Squared error', 'R2 Score'])\n",
    "accuracy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfZxqyuc0GKv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Avaliacao experimental.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
