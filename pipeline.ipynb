{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diamonds = pd.read_csv('datasets/diamonds.csv')\n",
    "df_diamonds.drop(columns={\"Unnamed: 0\"}, inplace=True)\n",
    "df_diamonds[\"price\"] = df_diamonds[\"price\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_diamonds.drop('price', axis=1)\n",
    "X['carat'] = np.log2(X['carat'])\n",
    "y = np.log2(df_diamonds['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = {\n",
    "    \"cut\": [\"Ideal\",\"Premium\", \"Very Good\", \"Good\", \"Fair\"],\n",
    "    \"color\": [\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"],\n",
    "    \"clarity\": [\"IF\", \"VVS1\", \"VVS2\", \"VS1\", \"VS2\", \"SI1\", \"SI2\", \"I1\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_numericos = X_train.select_dtypes('float').columns.tolist()\n",
    "transformer_numerico = StandardScaler()\n",
    "\n",
    "atributos_categoricos = X_train.select_dtypes('O').columns.tolist()\n",
    "#transformer_categorico = OneHotEncoder(handle_unknown='ignore')\n",
    "categorias = [[\"Fair\",\"Good\", \"Very Good\", \"Premium\", \"Ideal\"],\n",
    "              [\"J\",\"I\",\"H\",\"G\",\"F\",\"E\",\"D\"],\n",
    "              [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]]\n",
    "\n",
    "transformer_categorico = OrdinalEncoder()\n",
    "\n",
    "selecao_atributos = SelectFromModel(DecisionTreeRegressor(random_state=42),threshold=0.001, max_features=9)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', transformer_numerico, atributos_numericos),\n",
    "        ('cat', transformer_categorico, atributos_categoricos)])\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])#, ('selecao_atributos', selecao_atributos)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seletor = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pipeline.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = (X_train, X_test, y_train, y_test, 'dataset_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=[]\n",
    "model_=[]\n",
    "cv_score_test=[]\n",
    "cv_score_train=[]\n",
    "mse_=[]\n",
    "mae_=[]\n",
    "rmse_=[]\n",
    "r2_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, dataset, modelname):\n",
    "    model.fit(dataset[0], dataset[2])\n",
    "    accuracies=cross_val_score(estimator=model, X=dataset[0], y=dataset[2], cv=5, verbose=1, n_jobs=-1)\n",
    "    y_pred=model.predict(dataset[1])\n",
    "    print('')\n",
    "    score_1=model.score(dataset[1], dataset[3])\n",
    "    print(f'#### {modelname} ####')\n",
    "    print(\"score :%.4f\" %score_1)\n",
    "    print(accuracies)\n",
    "    \n",
    "    \n",
    "    mse=mean_squared_error(dataset[3], y_pred)\n",
    "    mae=mean_absolute_error(dataset[3], y_pred)\n",
    "    rmse=mean_squared_error(dataset[3], y_pred)**0.5\n",
    "    r2=r2_score(dataset[3], y_pred)\n",
    "    \n",
    "    print('')\n",
    "    print('MSE    : %0.2f ' % mse)\n",
    "    print('MAE    : %0.2f ' % mae)\n",
    "    print('RMSE   : %0.2f ' % rmse)\n",
    "    print('R2     : %0.2f ' % r2)\n",
    "    \n",
    "    ## appending to the lists\n",
    "    \n",
    "    model_name.append(modelname)\n",
    "    model_.append(model)\n",
    "    cv_score_test.append(score_1)\n",
    "    cv_score_train.append(np.mean(accuracies))\n",
    "    mse_.append(mse)\n",
    "    mae_.append(mae)\n",
    "    rmse_.append(rmse)\n",
    "    r2_.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict={'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "            'AdaBoostRegressor': AdaBoostRegressor(n_estimators=1000),\n",
    "            'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "            'RandomForestRegressor': RandomForestRegressor(),\n",
    "            'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "            'MLPRegressor': MLPRegressor(hidden_layer_sizes=(200, 100,), batch_size=100, learning_rate_init=0.004, learning_rate=\"adaptive\", max_iter=700, verbose=True)\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### DecisionTreeRegressor ####\n",
      "score :0.9850\n",
      "[0.98458885 0.98312925 0.98488688 0.98324379 0.98382069]\n",
      "\n",
      "MSE    : 0.03 \n",
      "MAE    : 0.12 \n",
      "RMSE   : 0.18 \n",
      "R2     : 0.99 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### AdaBoostRegressor ####\n",
      "score :0.9322\n",
      "[0.93350074 0.9329071  0.93594907 0.93793159 0.93226008]\n",
      "\n",
      "MSE    : 0.14 \n",
      "MAE    : 0.30 \n",
      "RMSE   : 0.38 \n",
      "R2     : 0.93 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### GradientBoostingRegressor ####\n",
      "score :0.9875\n",
      "[0.98680034 0.98664751 0.98831835 0.98622824 0.98686759]\n",
      "\n",
      "MSE    : 0.03 \n",
      "MAE    : 0.13 \n",
      "RMSE   : 0.16 \n",
      "R2     : 0.99 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   42.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### RandomForestRegressor ####\n",
      "score :0.9921\n",
      "[0.99168294 0.99148562 0.99249872 0.99055615 0.99120019]\n",
      "\n",
      "MSE    : 0.02 \n",
      "MAE    : 0.09 \n",
      "RMSE   : 0.13 \n",
      "R2     : 0.99 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### KNeighborsRegressor ####\n",
      "score :0.9801\n",
      "[0.97941677 0.97867443 0.97940184 0.97766658 0.97829633]\n",
      "\n",
      "MSE    : 0.04 \n",
      "MAE    : 0.15 \n",
      "RMSE   : 0.20 \n",
      "R2     : 0.98 \n",
      "Iteration 1, loss = 0.93449911\n",
      "Iteration 2, loss = 0.03715466\n",
      "Iteration 3, loss = 0.03457328\n",
      "Iteration 4, loss = 0.03217330\n",
      "Iteration 5, loss = 0.02781067\n",
      "Iteration 6, loss = 0.02781307\n",
      "Iteration 7, loss = 0.02679945\n",
      "Iteration 8, loss = 0.02753616\n",
      "Iteration 9, loss = 0.02786726\n",
      "Iteration 10, loss = 0.02830597\n",
      "Iteration 11, loss = 0.04626015\n",
      "Iteration 12, loss = 0.02747418\n",
      "Iteration 13, loss = 0.02420441\n",
      "Iteration 14, loss = 0.02234041\n",
      "Iteration 15, loss = 0.02183025\n",
      "Iteration 16, loss = 0.02255245\n",
      "Iteration 17, loss = 0.02156146\n",
      "Iteration 18, loss = 0.02190263\n",
      "Iteration 19, loss = 0.02268984\n",
      "Iteration 20, loss = 0.02900792\n",
      "Iteration 21, loss = 0.02048845\n",
      "Iteration 22, loss = 0.02210503\n",
      "Iteration 23, loss = 0.02033056\n",
      "Iteration 24, loss = 0.02200875\n",
      "Iteration 25, loss = 0.02724946\n",
      "Iteration 26, loss = 0.02032974\n",
      "Iteration 27, loss = 0.01962090\n",
      "Iteration 28, loss = 0.01853457\n",
      "Iteration 29, loss = 0.01873539\n",
      "Iteration 30, loss = 0.02052470\n",
      "Iteration 31, loss = 0.01766552\n",
      "Iteration 32, loss = 0.01702713\n",
      "Iteration 33, loss = 0.01672085\n",
      "Iteration 34, loss = 0.01735775\n",
      "Iteration 35, loss = 0.01603971\n",
      "Iteration 36, loss = 0.01569961\n",
      "Iteration 37, loss = 0.01555931\n",
      "Iteration 38, loss = 0.01499647\n",
      "Iteration 39, loss = 0.01560760\n",
      "Iteration 40, loss = 0.01502972\n",
      "Iteration 41, loss = 0.01576932\n",
      "Iteration 42, loss = 0.01542340\n",
      "Iteration 43, loss = 0.01451198\n",
      "Iteration 44, loss = 0.01399734\n",
      "Iteration 45, loss = 0.01395752\n",
      "Iteration 46, loss = 0.01477057\n",
      "Iteration 47, loss = 0.01387002\n",
      "Iteration 48, loss = 0.01349899\n",
      "Iteration 49, loss = 0.01406849\n",
      "Iteration 50, loss = 0.02041624\n",
      "Iteration 51, loss = 0.01552403\n",
      "Iteration 52, loss = 0.01389356\n",
      "Iteration 53, loss = 0.01385996\n",
      "Iteration 54, loss = 0.01350313\n",
      "Iteration 55, loss = 0.01479624\n",
      "Iteration 56, loss = 0.01439510\n",
      "Iteration 57, loss = 0.01323644\n",
      "Iteration 58, loss = 0.01291277\n",
      "Iteration 59, loss = 0.01346648\n",
      "Iteration 60, loss = 0.01314072\n",
      "Iteration 61, loss = 0.01305275\n",
      "Iteration 62, loss = 0.01301241\n",
      "Iteration 63, loss = 0.01258805\n",
      "Iteration 64, loss = 0.01278331\n",
      "Iteration 65, loss = 0.01333804\n",
      "Iteration 66, loss = 0.01300619\n",
      "Iteration 67, loss = 0.01262581\n",
      "Iteration 68, loss = 0.01347920\n",
      "Iteration 69, loss = 0.01224877\n",
      "Iteration 70, loss = 0.01230216\n",
      "Iteration 71, loss = 0.01251236\n",
      "Iteration 72, loss = 0.01288109\n",
      "Iteration 73, loss = 0.01232453\n",
      "Iteration 74, loss = 0.01433906\n",
      "Iteration 75, loss = 0.01260045\n",
      "Iteration 76, loss = 0.01231612\n",
      "Iteration 77, loss = 0.01170082\n",
      "Iteration 78, loss = 0.01275362\n",
      "Iteration 79, loss = 0.01277815\n",
      "Iteration 80, loss = 0.01313859\n",
      "Iteration 81, loss = 0.01251420\n",
      "Iteration 82, loss = 0.01233926\n",
      "Iteration 83, loss = 0.01201140\n",
      "Iteration 84, loss = 0.01246464\n",
      "Iteration 85, loss = 0.01233165\n",
      "Iteration 86, loss = 0.01208994\n",
      "Iteration 87, loss = 0.01217271\n",
      "Iteration 88, loss = 0.01190216\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### MLPRegressor ####\n",
      "score :0.9891\n",
      "[0.98741043 0.98682037 0.98899378 0.98912065 0.98179349]\n",
      "\n",
      "MSE    : 0.02 \n",
      "MAE    : 0.11 \n",
      "RMSE   : 0.15 \n",
      "R2     : 0.99 \n"
     ]
    }
   ],
   "source": [
    "for models in model_dict:\n",
    "    run_model(model_dict[models], dataset_1, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NECESS√ÅRIO ENTENDER SE FAZ SENTIDO USAR LOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
